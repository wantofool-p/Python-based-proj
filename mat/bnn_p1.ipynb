{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy import linalg as LA\n",
    "import os\n",
    "import urllib.request\n",
    "import colorama\n",
    "from colorama import Fore, Style\n",
    "import csv\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset,DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"微软雅黑\" size=5 color=#A52A2A >Task1: Data preparation and display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Real(h)_1</th>\n",
       "      <th>Real(h)_2</th>\n",
       "      <th>Real(h)_3</th>\n",
       "      <th>Real(h)_4</th>\n",
       "      <th>Real(h)_5</th>\n",
       "      <th>Real(h)_6</th>\n",
       "      <th>Real(h)_7</th>\n",
       "      <th>Real(h)_8</th>\n",
       "      <th>Real(h)_9</th>\n",
       "      <th>Real(h)_10</th>\n",
       "      <th>...</th>\n",
       "      <th>Imag(h)_19</th>\n",
       "      <th>Imag(h)_20</th>\n",
       "      <th>Imag(h)_21</th>\n",
       "      <th>Imag(h)_22</th>\n",
       "      <th>Imag(h)_23</th>\n",
       "      <th>Imag(h)_24</th>\n",
       "      <th>q_1</th>\n",
       "      <th>q_2</th>\n",
       "      <th>q_3</th>\n",
       "      <th>q_4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>No</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.020829</td>\n",
       "      <td>-41.950315</td>\n",
       "      <td>11.304785</td>\n",
       "      <td>4.916935</td>\n",
       "      <td>6.917294</td>\n",
       "      <td>5.262758</td>\n",
       "      <td>-10.742547</td>\n",
       "      <td>6.272788</td>\n",
       "      <td>0.781039</td>\n",
       "      <td>48.216098</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.310428</td>\n",
       "      <td>5.749396</td>\n",
       "      <td>-6.596871</td>\n",
       "      <td>36.595822</td>\n",
       "      <td>8.692891</td>\n",
       "      <td>8.919924</td>\n",
       "      <td>0.712941</td>\n",
       "      <td>0.004418</td>\n",
       "      <td>0.157381</td>\n",
       "      <td>0.125260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11.989581</td>\n",
       "      <td>-4.038581</td>\n",
       "      <td>0.574468</td>\n",
       "      <td>5.078650</td>\n",
       "      <td>17.227288</td>\n",
       "      <td>15.862075</td>\n",
       "      <td>-9.494032</td>\n",
       "      <td>-8.335850</td>\n",
       "      <td>-0.016623</td>\n",
       "      <td>-50.099146</td>\n",
       "      <td>...</td>\n",
       "      <td>5.483431</td>\n",
       "      <td>-2.406380</td>\n",
       "      <td>-7.550119</td>\n",
       "      <td>-19.652089</td>\n",
       "      <td>1.705091</td>\n",
       "      <td>-2.249488</td>\n",
       "      <td>0.113186</td>\n",
       "      <td>0.013086</td>\n",
       "      <td>0.396980</td>\n",
       "      <td>0.476748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.797186</td>\n",
       "      <td>1.626110</td>\n",
       "      <td>50.091571</td>\n",
       "      <td>22.412621</td>\n",
       "      <td>-4.083873</td>\n",
       "      <td>-1.277553</td>\n",
       "      <td>-56.697669</td>\n",
       "      <td>11.935711</td>\n",
       "      <td>1.645857</td>\n",
       "      <td>1.070870</td>\n",
       "      <td>...</td>\n",
       "      <td>0.121436</td>\n",
       "      <td>3.992097</td>\n",
       "      <td>2.150922</td>\n",
       "      <td>-8.683767</td>\n",
       "      <td>4.323549</td>\n",
       "      <td>-0.442214</td>\n",
       "      <td>0.100918</td>\n",
       "      <td>0.788928</td>\n",
       "      <td>0.008065</td>\n",
       "      <td>0.102089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.523107</td>\n",
       "      <td>-4.617390</td>\n",
       "      <td>8.435654</td>\n",
       "      <td>1.237661</td>\n",
       "      <td>25.271087</td>\n",
       "      <td>6.760474</td>\n",
       "      <td>50.205191</td>\n",
       "      <td>5.272745</td>\n",
       "      <td>-10.572534</td>\n",
       "      <td>-16.605411</td>\n",
       "      <td>...</td>\n",
       "      <td>26.575939</td>\n",
       "      <td>2.634083</td>\n",
       "      <td>-0.018737</td>\n",
       "      <td>-0.160407</td>\n",
       "      <td>-69.141834</td>\n",
       "      <td>5.105702</td>\n",
       "      <td>0.091481</td>\n",
       "      <td>0.120804</td>\n",
       "      <td>0.005015</td>\n",
       "      <td>0.782699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.746797</td>\n",
       "      <td>-7.205020</td>\n",
       "      <td>-8.552247</td>\n",
       "      <td>1.222384</td>\n",
       "      <td>4.219274</td>\n",
       "      <td>-5.546848</td>\n",
       "      <td>-4.124834</td>\n",
       "      <td>6.571589</td>\n",
       "      <td>1.335697</td>\n",
       "      <td>30.289894</td>\n",
       "      <td>...</td>\n",
       "      <td>26.650121</td>\n",
       "      <td>-2.186115</td>\n",
       "      <td>-0.969020</td>\n",
       "      <td>-16.074266</td>\n",
       "      <td>23.099630</td>\n",
       "      <td>1.324784</td>\n",
       "      <td>0.411339</td>\n",
       "      <td>0.013081</td>\n",
       "      <td>0.051570</td>\n",
       "      <td>0.524010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Real(h)_1  Real(h)_2  Real(h)_3  Real(h)_4  Real(h)_5  Real(h)_6  \\\n",
       "No                                                                     \n",
       "1    0.020829 -41.950315  11.304785   4.916935   6.917294   5.262758   \n",
       "2   11.989581  -4.038581   0.574468   5.078650  17.227288  15.862075   \n",
       "3   -0.797186   1.626110  50.091571  22.412621  -4.083873  -1.277553   \n",
       "4   20.523107  -4.617390   8.435654   1.237661  25.271087   6.760474   \n",
       "5    6.746797  -7.205020  -8.552247   1.222384   4.219274  -5.546848   \n",
       "\n",
       "    Real(h)_7  Real(h)_8  Real(h)_9  Real(h)_10  ...  Imag(h)_19  Imag(h)_20  \\\n",
       "No                                               ...                           \n",
       "1  -10.742547   6.272788   0.781039   48.216098  ...   -0.310428    5.749396   \n",
       "2   -9.494032  -8.335850  -0.016623  -50.099146  ...    5.483431   -2.406380   \n",
       "3  -56.697669  11.935711   1.645857    1.070870  ...    0.121436    3.992097   \n",
       "4   50.205191   5.272745 -10.572534  -16.605411  ...   26.575939    2.634083   \n",
       "5   -4.124834   6.571589   1.335697   30.289894  ...   26.650121   -2.186115   \n",
       "\n",
       "    Imag(h)_21  Imag(h)_22  Imag(h)_23  Imag(h)_24       q_1       q_2  \\\n",
       "No                                                                       \n",
       "1    -6.596871   36.595822    8.692891    8.919924  0.712941  0.004418   \n",
       "2    -7.550119  -19.652089    1.705091   -2.249488  0.113186  0.013086   \n",
       "3     2.150922   -8.683767    4.323549   -0.442214  0.100918  0.788928   \n",
       "4    -0.018737   -0.160407  -69.141834    5.105702  0.091481  0.120804   \n",
       "5    -0.969020  -16.074266   23.099630    1.324784  0.411339  0.013081   \n",
       "\n",
       "         q_3       q_4  \n",
       "No                      \n",
       "1   0.157381  0.125260  \n",
       "2   0.396980  0.476748  \n",
       "3   0.008065  0.102089  \n",
       "4   0.005015  0.782699  \n",
       "5   0.051570  0.524010  \n",
       "\n",
       "[5 rows x 52 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dataset(index()+real_part(24)+imaginary_part(24)+q(4))\n",
    "raw_data=pd.read_csv('MyData_25000.csv')\n",
    "df=pd.DataFrame(raw_data)\n",
    "df=df.set_index('No')\n",
    "df.head(5)\n",
    "#df.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#supress warnings\n",
    "import warnings \n",
    "from pandas.core.common import SettingWithCopyWarning\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\", category=SettingWithCopyWarning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get h matrix(2*24) input and column q vector(4*1) output\n",
    "def parse_data(df,N,K,form): \n",
    "    df_c=df.copy()\n",
    "    for k in range(N*K): #0-23\n",
    "        df_c['Real(h)_'+str(k+1)] = df_c['Real(h)_'+str(k+1)].astype(form)\n",
    "        df_c['Imag(h)_'+str(k+1)] = df_c['Imag(h)_'+str(k+1)].astype(form)\n",
    "        if k<=3: #0-3\n",
    "            df_c['q_'+str(k+1)] = df_c['q_'+str(k+1)].astype(form)\n",
    "        \n",
    "    df_c['h_ip']=[[]] * df.shape[0]#add new columns  \n",
    "    df_c['q_exp']=[[]] * df.shape[0]\n",
    "    real=[]\n",
    "    imag=[]\n",
    "    q_col=[]\n",
    "    for idx in range(len(df_c)):\n",
    "        for i in range(N*K):\n",
    "            real.append(df_c.iloc[idx]['Real(h)_'+str(i+1)])\n",
    "            imag.append(df_c.iloc[idx]['Imag(h)_'+str(i+1)])\n",
    "            if i<=3:\n",
    "                q_col.append([df_c.iloc[idx]['q_'+str(i+1)]])      \n",
    "            df_c.at[idx+1,'h_ip']=[real,imag]\n",
    "            df_c.at[idx+1,'q_exp']=q_col\n",
    "        real=[]\n",
    "        imag=[]\n",
    "        q_col=[]\n",
    "    for t in range(N*K):\n",
    "        df_c.drop('Real(h)_'+str(t+1),axis=1,inplace=True) #no need to keep after reshaping\n",
    "        df_c.drop('Imag(h)_'+str(t+1),axis=1,inplace=True)\n",
    "        if t<=3:\n",
    "            df_c.drop('q_'+str(t+1),axis=1,inplace=True) \n",
    "    return df_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>h_ip</th>\n",
       "      <th>q_exp</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>No</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[0.0208288733174387, -41.9503148729969, 11.30...</td>\n",
       "      <td>[[0.7129409417896541], [0.00441774112262481], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[11.9895810316306, -4.03858116245368, 0.57446...</td>\n",
       "      <td>[[0.11318635455657002], [0.0130859197889614], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[-0.797185851656008, 1.62610997703591, 50.091...</td>\n",
       "      <td>[[0.100918407171242], [0.7889278873124929], [0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[20.5231067503686, -4.61738966807714, 8.43565...</td>\n",
       "      <td>[[0.0914813174107049], [0.120804203424745], [0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[[6.74679662912277, -7.205020055273139, -8.552...</td>\n",
       "      <td>[[0.41133938547927296], [0.0130805982325663], ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 h_ip  \\\n",
       "No                                                      \n",
       "1   [[0.0208288733174387, -41.9503148729969, 11.30...   \n",
       "2   [[11.9895810316306, -4.03858116245368, 0.57446...   \n",
       "3   [[-0.797185851656008, 1.62610997703591, 50.091...   \n",
       "4   [[20.5231067503686, -4.61738966807714, 8.43565...   \n",
       "5   [[6.74679662912277, -7.205020055273139, -8.552...   \n",
       "\n",
       "                                                q_exp  \n",
       "No                                                     \n",
       "1   [[0.7129409417896541], [0.00441774112262481], ...  \n",
       "2   [[0.11318635455657002], [0.0130859197889614], ...  \n",
       "3   [[0.100918407171242], [0.7889278873124929], [0...  \n",
       "4   [[0.0914813174107049], [0.120804203424745], [0...  \n",
       "5   [[0.41133938547927296], [0.0130805982325663], ...  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reshaped dataset partly display\n",
    "N,K=6,4\n",
    "form=float\n",
    "df_c=parse_data(df,N,K,form).copy()\n",
    "df_c.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mh input shown as:\n",
      "\u001b[30m[[ 1.19895810e+01 -4.03858116e+00  5.74468454e-01  5.07865042e+00\n",
      "   1.72272878e+01  1.58620749e+01 -9.49403237e+00 -8.33585008e+00\n",
      "  -1.66234905e-02 -5.00991461e+01  3.65507381e+00  4.08385945e+00\n",
      "   6.32668040e+00 -2.62171380e+01 -4.46792980e-02  1.09319612e+01\n",
      "   1.65333515e+01 -3.75703660e+01 -6.27894605e+00  4.31542211e-01\n",
      "  -1.77479800e+01  3.08630702e+00  4.00718646e+00 -1.21261917e+00]\n",
      " [ 6.42273961e+00  1.56075949e+01  3.32134597e+00 -3.62151558e+00\n",
      "  -1.25639474e+00  1.23407540e+01 -1.06952720e+01 -7.05975296e+00\n",
      "  -8.56067556e+00  2.51848138e+01 -3.46552598e+00 -2.92814889e+00\n",
      "   5.15426772e+00  6.52295796e+01 -9.14102594e+00 -1.04014101e+00\n",
      "   5.45715955e+00 -3.82909227e+01  5.48343068e+00 -2.40638033e+00\n",
      "  -7.55011867e+00 -1.96520888e+01  1.70509122e+00 -2.24948768e+00]]\n",
      "\u001b[34mq expected shown as:\n",
      "\u001b[30m[[0.11318635]\n",
      " [0.01308592]\n",
      " [0.3969799 ]\n",
      " [0.47674783]]\n"
     ]
    }
   ],
   "source": [
    "#dataset search/display\n",
    "data_index=2\n",
    "\n",
    "h_info=df_c.iloc[data_index-1]['h_ip']\n",
    "q_info=df_c.iloc[data_index-1]['q_exp']\n",
    "print(Fore.BLUE +'h input shown as:\\n'+Fore.BLACK+str(np.array(h_info))) #use array to show a clean format, originl data is nested lists\n",
    "print(Fore.BLUE +'q expected shown as:\\n'+Fore.BLACK+str(np.array(q_info)))\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000\n",
      "20000\n",
      "5000\n",
      "5000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train/test split-->0.8(20000)/0.2(5000),25000 samples in total\n",
    "h=df_c.drop(columns = ['q_exp']).copy()\n",
    "q=df_c['q_exp']\n",
    "\n",
    "train_ratio=0.8\n",
    "\n",
    "\n",
    "h_train, h_test, q_train, q_test = train_test_split(h,q, train_size=train_ratio)\n",
    "\n",
    "\n",
    "print(h_train.shape[0]), print(q_train.shape[0])\n",
    "print(h_test.shape[0]), print(q_test.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data to tensor for use\n",
    "import torch.utils.data as data_utils\n",
    "class Init_Data(Dataset):\n",
    "    def __init__(self,h_dataset,q_dataset):\n",
    "        h_data=h_dataset\n",
    "        q_data=q_dataset\n",
    "        self.len=h_data.shape[0]\n",
    "        self.h_data=torch.tensor(np.stack(h_data['h_ip']).astype(np.float64)) \n",
    "        self.q_data=torch.tensor(np.stack(q_data).astype(np.float64)) \n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        return self.h_data[index],self.q_data[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20000, 2, 24])\n",
      "torch.Size([20000, 4, 1])\n"
     ]
    }
   ],
   "source": [
    "#check tensor process works or not\n",
    "print(torch.tensor(np.stack(h_train['h_ip']).astype(np.float64)).size()),\n",
    "print(torch.tensor(np.stack(q_train).astype(np.float64)).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply as tensordata and load into dataloader\n",
    "train_data=Init_Data(h_train,q_train)\n",
    "test_data=Init_Data(h_test,q_test)\n",
    "\n",
    "\n",
    "train_loader=DataLoader(dataset=train_data,batch_size=200,\n",
    "                          shuffle=True,num_workers=0)\n",
    "test_loader=DataLoader(dataset=test_data,batch_size=200,\n",
    "                         shuffle=False,num_workers=0)\n",
    "\n",
    "#next(iter(train_loader)) #h_train+q_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"微软雅黑\" size=5 color=#A52A2A >Task2: Module Completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BNN_P1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BNN_P1,self).__init__()\n",
    "        self.conv1=nn.Conv2d(1,8,kernel_size=3,stride=1,padding=1,bias=True)         #layer 2, convolutional \n",
    "        self.bn1=nn.BatchNorm2d(8,eps=1e-03, momentum=0.99)                          #layer 3,batch normalization\n",
    "        self.conv2=nn.Conv2d(8,8,kernel_size=3,stride=1,padding=1,bias=True)        #layer 5,convolutional\n",
    "        self.bn2=nn.BatchNorm2d(8,eps=1e-03, momentum=0.99)                         #layer 7,batch normalization\n",
    "        self.fc1=nn.Linear(384,4)                                                   #layer 9,fully connected\n",
    "        self.sigmoid=nn.Sigmoid()                                                  #layer 10,sigmoid\n",
    "        \n",
    "    def forward(self,x):\n",
    "        batch_size=x.size(0)\n",
    "        x=self.conv1(x)\n",
    "#         print(self.conv1.weight.size())           #torch.Size([8, 1, 3, 3])\n",
    "#        print(self.conv1.bias.size())              #torch.Size([8])\n",
    "#         print(x.shape)                         #torch.Size([200, 8, 2, 24])\n",
    "        x=self.bn1(x)\n",
    "#         print(x.shape)                         #torch.Size([200, 8, 2, 24])\n",
    "        x=x=F.relu(x)                         #layer 4, ReLU activation\n",
    "#         print(x.shape)                         #torch.Size([200, 8, 2, 24])\n",
    "        x=self.conv2(x)\n",
    "#         print(self.conv2.weight.size())           #torch.Size([8, 8, 3, 3])\n",
    "#         print(self.conv2.bias.size())            #torch.Size([8])\n",
    "#         print(x.shape)                         #torch.Size([200, 8, 2, 24])\n",
    "        x=self.bn2(x)\n",
    "#         print(x.shape)                         #torch.Size([200, 8, 2, 24])\n",
    "        x=x=F.relu(x)                         #layer 6, ReLU activation\n",
    "#         print(x.shape)                         #torch.Size([200, 8, 2, 24])\n",
    "        x=x.view(batch_size,-1)               #layer 8,flatten \n",
    "#         print(x.shape)                        #torch.Size([200, 384])\n",
    "        x=self.fc1(x)\n",
    "#         print(x.shape)                        #torch.Size([200, 4])\n",
    "        x=self.sigmoid(x)            \n",
    "        x=x.unsqueeze(-1)                     #output layer, 4 feature to [4,1]\n",
    "#         print(x.shape)                        #torch.Size([200, 4, 1])\n",
    "        \n",
    "        \n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    " #Glorot normal inintializer for weights and bias initialized to 0\n",
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        torch.nn.init.xavier_uniform_(m.weight)\n",
    "        m.bias.data.fill_(0.01)\n",
    "    elif isinstance(m, nn.Conv2d):\n",
    "        torch.nn.init.xavier_uniform_(m.weight)\n",
    "        m.bias.data.fill_(0.01)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"微软雅黑\" size=5 color=#A52A2A >Task3: Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BNN_P1(\n",
       "  (conv1): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn1): BatchNorm2d(8, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "  (conv2): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn2): BatchNorm2d(8, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "  (fc1): Linear(in_features=384, out_features=4, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model structure display\n",
    "model=BNN_P1()\n",
    "model=model.double()\n",
    "model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion=torch.nn.MSELoss() #default reduction='Mean' \n",
    "optimizer=optim.Adam(model.parameters(),lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    running_loss=0.0\n",
    "    for batch_idx,data in enumerate(train_loader,0):\n",
    "        inputs,target=data\n",
    "        optimizer.zero_grad()\n",
    "        #forward\n",
    "        inputs =inputs.unsqueeze(1) #add one dimension(channel)\n",
    "        q_pred=model(inputs)\n",
    "        #backward\n",
    "        #target = target.unsqueeze(1)\n",
    "        loss=criterion(q_pred,target)\n",
    "#         print(target.size())\n",
    "#         print(q_pred.size())\n",
    "        loss.backward()\n",
    "        #update\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss+=loss.item()\n",
    "        if batch_idx%50==49: #100 iteration with batch size 200 by 20000 training samples, print loss every 50 iterations\n",
    "            print('[%d,%9d] loss: %.9f'%(epoch+1,batch_idx+1,running_loss/200)) #mention the epoch index\n",
    "            running_loss=0.0\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_default_check(): #without traning, check what happened and the accuracy performance\n",
    "    correct=0\n",
    "    total=0\n",
    "    check_point=0\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            original_input,labels=data\n",
    "#             print(len(original_input))\n",
    "#             print(len(labels))\n",
    "#             print(original_input[1])\n",
    "#             print(labels[1])\n",
    "            ip3 =original_input.unsqueeze(1)\n",
    "            outputs=model(ip3)\n",
    "            predicted=outputs.data\n",
    "            total+=labels.size(0)\n",
    "            print(model.parameters())\n",
    "#             print(predicted[1])\n",
    "#             print(labels[1])\n",
    "#             print(abs(LA.norm(predicted[1]-labels[1]))**2)\n",
    "#             print((abs(LA.norm(predicted[1]-labels[1]))**2)<=0.01)\n",
    "            \n",
    "            for i in range(predicted.size(0)):\n",
    "                if bool((abs(LA.norm(predicted[i]-labels[i]))**2)<=0.01): #error bearance\n",
    "                    correct+=1\n",
    "            check_point+=1\n",
    "            print(36*'-'+'Check point '+str(check_point)+36*'-')\n",
    "    \n",
    "    print('Accuracy on test set: %d %% [%d/%d]'%(100*correct/total,correct,total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    correct=0\n",
    "    total=0\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            original_input,labels=data\n",
    "            ip3 =original_input.unsqueeze(1)\n",
    "            outputs=model(ip3)\n",
    "            predicted=outputs.data\n",
    "            total+=labels.size(0)\n",
    "            for i in range(predicted.size(0)):\n",
    "                if bool((abs(LA.norm(predicted[i]-labels[i]))**2)<=0.01):\n",
    "                    correct+=1 \n",
    "    present_accuracy=100*correct/total\n",
    "    print('Accuracy on test set: %d %% [%d/%d]'%(present_accuracy,correct,total))\n",
    "\n",
    "    torch.save(model.state_dict(), 'best-model-parameters.pt')\n",
    "    torch.save(optimizer.state_dict(), 'best-optimizer-parameters.pt')\n",
    "    print(Fore.RED+'Model parameters and optimizer saved this point with accuracy: %.3f %%' %(present_accuracy)+Fore.BLACK)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object Module.parameters at 0x0000015A86566F90>\n",
      "------------------------------------Check point 1------------------------------------\n",
      "<generator object Module.parameters at 0x0000015A86566900>\n",
      "------------------------------------Check point 2------------------------------------\n",
      "<generator object Module.parameters at 0x0000015A86566900>\n",
      "------------------------------------Check point 3------------------------------------\n",
      "<generator object Module.parameters at 0x0000015A86566900>\n",
      "------------------------------------Check point 4------------------------------------\n",
      "<generator object Module.parameters at 0x0000015A86566900>\n",
      "------------------------------------Check point 5------------------------------------\n",
      "<generator object Module.parameters at 0x0000015A86566900>\n",
      "------------------------------------Check point 6------------------------------------\n",
      "<generator object Module.parameters at 0x0000015A86566900>\n",
      "------------------------------------Check point 7------------------------------------\n",
      "<generator object Module.parameters at 0x0000015A86566900>\n",
      "------------------------------------Check point 8------------------------------------\n",
      "<generator object Module.parameters at 0x0000015A86566900>\n",
      "------------------------------------Check point 9------------------------------------\n",
      "<generator object Module.parameters at 0x0000015A86566900>\n",
      "------------------------------------Check point 10------------------------------------\n",
      "<generator object Module.parameters at 0x0000015A86566900>\n",
      "------------------------------------Check point 11------------------------------------\n",
      "<generator object Module.parameters at 0x0000015A86566900>\n",
      "------------------------------------Check point 12------------------------------------\n",
      "<generator object Module.parameters at 0x0000015A86566900>\n",
      "------------------------------------Check point 13------------------------------------\n",
      "<generator object Module.parameters at 0x0000015A86566900>\n",
      "------------------------------------Check point 14------------------------------------\n",
      "<generator object Module.parameters at 0x0000015A86566900>\n",
      "------------------------------------Check point 15------------------------------------\n",
      "<generator object Module.parameters at 0x0000015A86566900>\n",
      "------------------------------------Check point 16------------------------------------\n",
      "<generator object Module.parameters at 0x0000015A86566900>\n",
      "------------------------------------Check point 17------------------------------------\n",
      "<generator object Module.parameters at 0x0000015A86566900>\n",
      "------------------------------------Check point 18------------------------------------\n",
      "<generator object Module.parameters at 0x0000015A86566900>\n",
      "------------------------------------Check point 19------------------------------------\n",
      "<generator object Module.parameters at 0x0000015A81C252E0>\n",
      "------------------------------------Check point 20------------------------------------\n",
      "<generator object Module.parameters at 0x0000015A81C252E0>\n",
      "------------------------------------Check point 21------------------------------------\n",
      "<generator object Module.parameters at 0x0000015A81C252E0>\n",
      "------------------------------------Check point 22------------------------------------\n",
      "<generator object Module.parameters at 0x0000015A81C252E0>\n",
      "------------------------------------Check point 23------------------------------------\n",
      "<generator object Module.parameters at 0x0000015A81C252E0>\n",
      "------------------------------------Check point 24------------------------------------\n",
      "<generator object Module.parameters at 0x0000015A81C252E0>\n",
      "------------------------------------Check point 25------------------------------------\n",
      "Accuracy on test set: 37 % [1877/5000]\n"
     ]
    }
   ],
   "source": [
    "if __name__=='__main__':\n",
    "    epoch=100\n",
    "    test_default_check() #without training   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,       50] loss: 0.018887539\n",
      "[1,      100] loss: 0.012500345\n",
      "Accuracy on test set: 1 % [55/5000]\n",
      "\u001b[31mModel parameters and optimizer saved this point with accuracy: 1.100 %\u001b[30m\n",
      "[2,       50] loss: 0.009257875\n",
      "[2,      100] loss: 0.006884920\n",
      "Accuracy on test set: 6 % [329/5000]\n",
      "\u001b[31mModel parameters and optimizer saved this point with accuracy: 6.580 %\u001b[30m\n",
      "[3,       50] loss: 0.004927477\n",
      "[3,      100] loss: 0.003855766\n",
      "Accuracy on test set: 14 % [730/5000]\n",
      "\u001b[31mModel parameters and optimizer saved this point with accuracy: 14.600 %\u001b[30m\n",
      "[4,       50] loss: 0.003265832\n",
      "[4,      100] loss: 0.002882821\n",
      "Accuracy on test set: 20 % [1000/5000]\n",
      "\u001b[31mModel parameters and optimizer saved this point with accuracy: 20.000 %\u001b[30m\n",
      "[5,       50] loss: 0.002616594\n",
      "[5,      100] loss: 0.002524519\n",
      "Accuracy on test set: 23 % [1156/5000]\n",
      "\u001b[31mModel parameters and optimizer saved this point with accuracy: 23.120 %\u001b[30m\n",
      "[6,       50] loss: 0.002321927\n",
      "[6,      100] loss: 0.002287217\n",
      "Accuracy on test set: 24 % [1202/5000]\n",
      "\u001b[31mModel parameters and optimizer saved this point with accuracy: 24.040 %\u001b[30m\n",
      "[7,       50] loss: 0.002180468\n",
      "[7,      100] loss: 0.002091529\n",
      "Accuracy on test set: 26 % [1314/5000]\n",
      "\u001b[31mModel parameters and optimizer saved this point with accuracy: 26.280 %\u001b[30m\n",
      "[8,       50] loss: 0.002021665\n",
      "[8,      100] loss: 0.001984209\n",
      "Accuracy on test set: 28 % [1419/5000]\n",
      "\u001b[31mModel parameters and optimizer saved this point with accuracy: 28.380 %\u001b[30m\n",
      "[9,       50] loss: 0.001906523\n",
      "[9,      100] loss: 0.001925972\n",
      "Accuracy on test set: 29 % [1452/5000]\n",
      "\u001b[31mModel parameters and optimizer saved this point with accuracy: 29.040 %\u001b[30m\n",
      "[10,       50] loss: 0.001875758\n",
      "[10,      100] loss: 0.001823682\n",
      "Accuracy on test set: 28 % [1433/5000]\n",
      "\u001b[31mModel parameters and optimizer saved this point with accuracy: 28.660 %\u001b[30m\n",
      "[11,       50] loss: 0.001815917\n",
      "[11,      100] loss: 0.001779153\n",
      "Accuracy on test set: 30 % [1521/5000]\n",
      "\u001b[31mModel parameters and optimizer saved this point with accuracy: 30.420 %\u001b[30m\n",
      "[12,       50] loss: 0.001771936\n",
      "[12,      100] loss: 0.001748357\n",
      "Accuracy on test set: 31 % [1553/5000]\n",
      "\u001b[31mModel parameters and optimizer saved this point with accuracy: 31.060 %\u001b[30m\n",
      "[13,       50] loss: 0.001735780\n",
      "[13,      100] loss: 0.001724725\n",
      "Accuracy on test set: 31 % [1590/5000]\n",
      "\u001b[31mModel parameters and optimizer saved this point with accuracy: 31.800 %\u001b[30m\n",
      "[14,       50] loss: 0.001689699\n",
      "[14,      100] loss: 0.001717236\n",
      "Accuracy on test set: 31 % [1593/5000]\n",
      "\u001b[31mModel parameters and optimizer saved this point with accuracy: 31.860 %\u001b[30m\n",
      "[15,       50] loss: 0.001686834\n",
      "[15,      100] loss: 0.001678571\n",
      "Accuracy on test set: 32 % [1616/5000]\n",
      "\u001b[31mModel parameters and optimizer saved this point with accuracy: 32.320 %\u001b[30m\n",
      "[16,       50] loss: 0.001658636\n",
      "[16,      100] loss: 0.001657099\n",
      "Accuracy on test set: 32 % [1635/5000]\n",
      "\u001b[31mModel parameters and optimizer saved this point with accuracy: 32.700 %\u001b[30m\n",
      "[17,       50] loss: 0.001629770\n",
      "[17,      100] loss: 0.001659716\n",
      "Accuracy on test set: 33 % [1657/5000]\n",
      "\u001b[31mModel parameters and optimizer saved this point with accuracy: 33.140 %\u001b[30m\n",
      "[18,       50] loss: 0.001624547\n",
      "[18,      100] loss: 0.001640772\n",
      "Accuracy on test set: 33 % [1660/5000]\n",
      "\u001b[31mModel parameters and optimizer saved this point with accuracy: 33.200 %\u001b[30m\n",
      "[19,       50] loss: 0.001594212\n",
      "[19,      100] loss: 0.001635502\n",
      "Accuracy on test set: 33 % [1689/5000]\n",
      "\u001b[31mModel parameters and optimizer saved this point with accuracy: 33.780 %\u001b[30m\n",
      "[20,       50] loss: 0.001613482\n",
      "[20,      100] loss: 0.001597729\n",
      "Accuracy on test set: 33 % [1670/5000]\n",
      "\u001b[31mModel parameters and optimizer saved this point with accuracy: 33.400 %\u001b[30m\n",
      "[21,       50] loss: 0.001602402\n",
      "[21,      100] loss: 0.001595664\n",
      "Accuracy on test set: 35 % [1753/5000]\n",
      "\u001b[31mModel parameters and optimizer saved this point with accuracy: 35.060 %\u001b[30m\n",
      "[22,       50] loss: 0.001591310\n",
      "[22,      100] loss: 0.001564298\n",
      "Accuracy on test set: 34 % [1740/5000]\n",
      "\u001b[31mModel parameters and optimizer saved this point with accuracy: 34.800 %\u001b[30m\n",
      "[23,       50] loss: 0.001557080\n",
      "[23,      100] loss: 0.001583027\n",
      "Accuracy on test set: 35 % [1758/5000]\n",
      "\u001b[31mModel parameters and optimizer saved this point with accuracy: 35.160 %\u001b[30m\n",
      "[24,       50] loss: 0.001559882\n",
      "[24,      100] loss: 0.001571823\n",
      "Accuracy on test set: 35 % [1765/5000]\n",
      "\u001b[31mModel parameters and optimizer saved this point with accuracy: 35.300 %\u001b[30m\n",
      "[25,       50] loss: 0.001565190\n",
      "[25,      100] loss: 0.001552726\n",
      "Accuracy on test set: 35 % [1767/5000]\n",
      "\u001b[31mModel parameters and optimizer saved this point with accuracy: 35.340 %\u001b[30m\n",
      "[26,       50] loss: 0.001556663\n",
      "[26,      100] loss: 0.001548914\n",
      "Accuracy on test set: 35 % [1771/5000]\n",
      "\u001b[31mModel parameters and optimizer saved this point with accuracy: 35.420 %\u001b[30m\n",
      "[27,       50] loss: 0.001555100\n",
      "[27,      100] loss: 0.001535352\n",
      "Accuracy on test set: 36 % [1810/5000]\n",
      "\u001b[31mModel parameters and optimizer saved this point with accuracy: 36.200 %\u001b[30m\n",
      "[28,       50] loss: 0.001552344\n",
      "[28,      100] loss: 0.001537482\n",
      "Accuracy on test set: 36 % [1820/5000]\n",
      "\u001b[31mModel parameters and optimizer saved this point with accuracy: 36.400 %\u001b[30m\n",
      "[29,       50] loss: 0.001516877\n",
      "[29,      100] loss: 0.001544996\n",
      "Accuracy on test set: 36 % [1803/5000]\n",
      "\u001b[31mModel parameters and optimizer saved this point with accuracy: 36.060 %\u001b[30m\n",
      "[30,       50] loss: 0.001513997\n",
      "[30,      100] loss: 0.001529876\n",
      "Accuracy on test set: 35 % [1763/5000]\n",
      "\u001b[31mModel parameters and optimizer saved this point with accuracy: 35.260 %\u001b[30m\n",
      "[31,       50] loss: 0.001502026\n",
      "[31,      100] loss: 0.001540851\n",
      "Accuracy on test set: 36 % [1828/5000]\n",
      "\u001b[31mModel parameters and optimizer saved this point with accuracy: 36.560 %\u001b[30m\n",
      "[32,       50] loss: 0.001506523\n",
      "[32,      100] loss: 0.001519960\n",
      "Accuracy on test set: 36 % [1828/5000]\n",
      "\u001b[31mModel parameters and optimizer saved this point with accuracy: 36.560 %\u001b[30m\n",
      "[33,       50] loss: 0.001500240\n",
      "[33,      100] loss: 0.001534016\n",
      "Accuracy on test set: 36 % [1837/5000]\n",
      "\u001b[31mModel parameters and optimizer saved this point with accuracy: 36.740 %\u001b[30m\n",
      "[34,       50] loss: 0.001494365\n",
      "[34,      100] loss: 0.001531361\n",
      "Accuracy on test set: 36 % [1832/5000]\n",
      "\u001b[31mModel parameters and optimizer saved this point with accuracy: 36.640 %\u001b[30m\n",
      "[35,       50] loss: 0.001498791\n",
      "[35,      100] loss: 0.001514517\n",
      "Accuracy on test set: 37 % [1856/5000]\n",
      "\u001b[31mModel parameters and optimizer saved this point with accuracy: 37.120 %\u001b[30m\n",
      "[36,       50] loss: 0.001493059\n",
      "[36,      100] loss: 0.001518100\n",
      "Accuracy on test set: 36 % [1828/5000]\n",
      "\u001b[31mModel parameters and optimizer saved this point with accuracy: 36.560 %\u001b[30m\n",
      "[37,       50] loss: 0.001486849\n",
      "[37,      100] loss: 0.001516202\n",
      "Accuracy on test set: 36 % [1816/5000]\n",
      "\u001b[31mModel parameters and optimizer saved this point with accuracy: 36.320 %\u001b[30m\n",
      "[38,       50] loss: 0.001496378\n",
      "[38,      100] loss: 0.001502149\n",
      "Accuracy on test set: 37 % [1851/5000]\n",
      "\u001b[31mModel parameters and optimizer saved this point with accuracy: 37.020 %\u001b[30m\n",
      "[39,       50] loss: 0.001494989\n",
      "[39,      100] loss: 0.001503759\n",
      "Accuracy on test set: 37 % [1863/5000]\n",
      "\u001b[31mModel parameters and optimizer saved this point with accuracy: 37.260 %\u001b[30m\n",
      "[40,       50] loss: 0.001517184\n",
      "[40,      100] loss: 0.001478044\n",
      "Accuracy on test set: 36 % [1845/5000]\n",
      "\u001b[31mModel parameters and optimizer saved this point with accuracy: 36.900 %\u001b[30m\n",
      "[41,       50] loss: 0.001481915\n",
      "[41,      100] loss: 0.001504672\n",
      "Accuracy on test set: 36 % [1811/5000]\n",
      "\u001b[31mModel parameters and optimizer saved this point with accuracy: 36.220 %\u001b[30m\n",
      "[42,       50] loss: 0.001513025\n",
      "[42,      100] loss: 0.001477149\n",
      "Accuracy on test set: 36 % [1845/5000]\n",
      "\u001b[31mModel parameters and optimizer saved this point with accuracy: 36.900 %\u001b[30m\n",
      "[43,       50] loss: 0.001495097\n",
      "[43,      100] loss: 0.001492274\n",
      "Accuracy on test set: 37 % [1858/5000]\n",
      "\u001b[31mModel parameters and optimizer saved this point with accuracy: 37.160 %\u001b[30m\n",
      "[44,       50] loss: 0.001467778\n",
      "[44,      100] loss: 0.001512569\n",
      "Accuracy on test set: 37 % [1858/5000]\n",
      "\u001b[31mModel parameters and optimizer saved this point with accuracy: 37.160 %\u001b[30m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[45,       50] loss: 0.001463011\n",
      "[45,      100] loss: 0.001507866\n",
      "Accuracy on test set: 37 % [1857/5000]\n",
      "\u001b[31mModel parameters and optimizer saved this point with accuracy: 37.140 %\u001b[30m\n",
      "[46,       50] loss: 0.001463855\n",
      "[46,      100] loss: 0.001501673\n",
      "Accuracy on test set: 36 % [1821/5000]\n",
      "\u001b[31mModel parameters and optimizer saved this point with accuracy: 36.420 %\u001b[30m\n",
      "[47,       50] loss: 0.001496817\n",
      "[47,      100] loss: 0.001476389\n",
      "Accuracy on test set: 37 % [1885/5000]\n",
      "\u001b[31mModel parameters and optimizer saved this point with accuracy: 37.700 %\u001b[30m\n",
      "[48,       50] loss: 0.001483756\n",
      "[48,      100] loss: 0.001485746\n",
      "Accuracy on test set: 36 % [1848/5000]\n",
      "\u001b[31mModel parameters and optimizer saved this point with accuracy: 36.960 %\u001b[30m\n",
      "[49,       50] loss: 0.001463318\n",
      "[49,      100] loss: 0.001495931\n",
      "Accuracy on test set: 37 % [1879/5000]\n",
      "\u001b[31mModel parameters and optimizer saved this point with accuracy: 37.580 %\u001b[30m\n",
      "[50,       50] loss: 0.001461749\n",
      "[50,      100] loss: 0.001495000\n",
      "Accuracy on test set: 37 % [1854/5000]\n",
      "\u001b[31mModel parameters and optimizer saved this point with accuracy: 37.080 %\u001b[30m\n",
      "[51,       50] loss: 0.001467953\n",
      "[51,      100] loss: 0.001490936\n",
      "Accuracy on test set: 36 % [1846/5000]\n",
      "\u001b[31mModel parameters and optimizer saved this point with accuracy: 36.920 %\u001b[30m\n",
      "[52,       50] loss: 0.001458918\n",
      "[52,      100] loss: 0.001504412\n",
      "Accuracy on test set: 37 % [1887/5000]\n",
      "\u001b[31mModel parameters and optimizer saved this point with accuracy: 37.740 %\u001b[30m\n",
      "[53,       50] loss: 0.001471378\n",
      "[53,      100] loss: 0.001469753\n",
      "Accuracy on test set: 37 % [1878/5000]\n",
      "\u001b[31mModel parameters and optimizer saved this point with accuracy: 37.560 %\u001b[30m\n",
      "[54,       50] loss: 0.001468518\n",
      "[54,      100] loss: 0.001481710\n",
      "Accuracy on test set: 37 % [1879/5000]\n",
      "\u001b[31mModel parameters and optimizer saved this point with accuracy: 37.580 %\u001b[30m\n",
      "[55,       50] loss: 0.001474563\n",
      "[55,      100] loss: 0.001472232\n",
      "Accuracy on test set: 37 % [1890/5000]\n",
      "\u001b[31mModel parameters and optimizer saved this point with accuracy: 37.800 %\u001b[30m\n",
      "[56,       50] loss: 0.001445604\n",
      "[56,      100] loss: 0.001488421\n",
      "Accuracy on test set: 37 % [1883/5000]\n",
      "\u001b[31mModel parameters and optimizer saved this point with accuracy: 37.660 %\u001b[30m\n",
      "[57,       50] loss: 0.001462527\n",
      "[57,      100] loss: 0.001465260\n",
      "Accuracy on test set: 37 % [1853/5000]\n",
      "\u001b[31mModel parameters and optimizer saved this point with accuracy: 37.060 %\u001b[30m\n",
      "[58,       50] loss: 0.001435782\n",
      "[58,      100] loss: 0.001495692\n",
      "Accuracy on test set: 37 % [1870/5000]\n",
      "\u001b[31mModel parameters and optimizer saved this point with accuracy: 37.400 %\u001b[30m\n",
      "[59,       50] loss: 0.001456550\n",
      "[59,      100] loss: 0.001499417\n",
      "Accuracy on test set: 37 % [1888/5000]\n",
      "\u001b[31mModel parameters and optimizer saved this point with accuracy: 37.760 %\u001b[30m\n",
      "[60,       50] loss: 0.001459221\n",
      "[60,      100] loss: 0.001476912\n",
      "Accuracy on test set: 37 % [1890/5000]\n",
      "\u001b[31mModel parameters and optimizer saved this point with accuracy: 37.800 %\u001b[30m\n",
      "[61,       50] loss: 0.001446148\n",
      "[61,      100] loss: 0.001486202\n",
      "Accuracy on test set: 37 % [1866/5000]\n",
      "\u001b[31mModel parameters and optimizer saved this point with accuracy: 37.320 %\u001b[30m\n",
      "[62,       50] loss: 0.001461151\n",
      "[62,      100] loss: 0.001469531\n",
      "Accuracy on test set: 37 % [1867/5000]\n",
      "\u001b[31mModel parameters and optimizer saved this point with accuracy: 37.340 %\u001b[30m\n",
      "[63,       50] loss: 0.001469652\n",
      "[63,      100] loss: 0.001459942\n",
      "Accuracy on test set: 37 % [1886/5000]\n",
      "\u001b[31mModel parameters and optimizer saved this point with accuracy: 37.720 %\u001b[30m\n",
      "[64,       50] loss: 0.001469431\n",
      "[64,      100] loss: 0.001447618\n",
      "Accuracy on test set: 37 % [1896/5000]\n",
      "\u001b[31mModel parameters and optimizer saved this point with accuracy: 37.920 %\u001b[30m\n",
      "[65,       50] loss: 0.001447897\n",
      "[65,      100] loss: 0.001480334\n",
      "Accuracy on test set: 37 % [1892/5000]\n",
      "\u001b[31mModel parameters and optimizer saved this point with accuracy: 37.840 %\u001b[30m\n",
      "[66,       50] loss: 0.001467096\n",
      "[66,      100] loss: 0.001444161\n",
      "Accuracy on test set: 37 % [1884/5000]\n",
      "\u001b[31mModel parameters and optimizer saved this point with accuracy: 37.680 %\u001b[30m\n",
      "[67,       50] loss: 0.001457310\n",
      "[67,      100] loss: 0.001461250\n",
      "Accuracy on test set: 37 % [1857/5000]\n",
      "\u001b[31mModel parameters and optimizer saved this point with accuracy: 37.140 %\u001b[30m\n",
      "[68,       50] loss: 0.001431055\n",
      "[68,      100] loss: 0.001488941\n",
      "Accuracy on test set: 37 % [1892/5000]\n",
      "\u001b[31mModel parameters and optimizer saved this point with accuracy: 37.840 %\u001b[30m\n",
      "[69,       50] loss: 0.001445381\n",
      "[69,      100] loss: 0.001475865\n",
      "Accuracy on test set: 37 % [1890/5000]\n",
      "\u001b[31mModel parameters and optimizer saved this point with accuracy: 37.800 %\u001b[30m\n",
      "[70,       50] loss: 0.001446405\n",
      "[70,      100] loss: 0.001462576\n",
      "Accuracy on test set: 37 % [1890/5000]\n",
      "\u001b[31mModel parameters and optimizer saved this point with accuracy: 37.800 %\u001b[30m\n",
      "[71,       50] loss: 0.001437643\n",
      "[71,      100] loss: 0.001475210\n",
      "Accuracy on test set: 36 % [1844/5000]\n",
      "\u001b[31mModel parameters and optimizer saved this point with accuracy: 36.880 %\u001b[30m\n",
      "[72,       50] loss: 0.001443561\n",
      "[72,      100] loss: 0.001467593\n",
      "Accuracy on test set: 37 % [1890/5000]\n",
      "\u001b[31mModel parameters and optimizer saved this point with accuracy: 37.800 %\u001b[30m\n",
      "[73,       50] loss: 0.001442426\n",
      "[73,      100] loss: 0.001465148\n",
      "Accuracy on test set: 37 % [1868/5000]\n",
      "\u001b[31mModel parameters and optimizer saved this point with accuracy: 37.360 %\u001b[30m\n",
      "[74,       50] loss: 0.001481011\n",
      "[74,      100] loss: 0.001431129\n",
      "Accuracy on test set: 37 % [1875/5000]\n",
      "\u001b[31mModel parameters and optimizer saved this point with accuracy: 37.500 %\u001b[30m\n",
      "[75,       50] loss: 0.001467213\n",
      "[75,      100] loss: 0.001458652\n",
      "Accuracy on test set: 37 % [1877/5000]\n",
      "\u001b[31mModel parameters and optimizer saved this point with accuracy: 37.540 %\u001b[30m\n",
      "[76,       50] loss: 0.001451961\n",
      "[76,      100] loss: 0.001445999\n",
      "Accuracy on test set: 37 % [1860/5000]\n",
      "\u001b[31mModel parameters and optimizer saved this point with accuracy: 37.200 %\u001b[30m\n",
      "[77,       50] loss: 0.001433678\n",
      "[77,      100] loss: 0.001473291\n",
      "Accuracy on test set: 37 % [1894/5000]\n",
      "\u001b[31mModel parameters and optimizer saved this point with accuracy: 37.880 %\u001b[30m\n",
      "[78,       50] loss: 0.001421737\n",
      "[78,      100] loss: 0.001491510\n",
      "Accuracy on test set: 37 % [1890/5000]\n",
      "\u001b[31mModel parameters and optimizer saved this point with accuracy: 37.800 %\u001b[30m\n",
      "[79,       50] loss: 0.001448468\n",
      "[79,      100] loss: 0.001451210\n",
      "Accuracy on test set: 37 % [1870/5000]\n",
      "\u001b[31mModel parameters and optimizer saved this point with accuracy: 37.400 %\u001b[30m\n",
      "[80,       50] loss: 0.001451537\n",
      "[80,      100] loss: 0.001453745\n",
      "Accuracy on test set: 37 % [1881/5000]\n",
      "\u001b[31mModel parameters and optimizer saved this point with accuracy: 37.620 %\u001b[30m\n",
      "[81,       50] loss: 0.001435589\n",
      "[81,      100] loss: 0.001461677\n",
      "Accuracy on test set: 37 % [1891/5000]\n",
      "\u001b[31mModel parameters and optimizer saved this point with accuracy: 37.820 %\u001b[30m\n",
      "[82,       50] loss: 0.001453935\n",
      "[82,      100] loss: 0.001435631\n",
      "Accuracy on test set: 38 % [1911/5000]\n",
      "\u001b[31mModel parameters and optimizer saved this point with accuracy: 38.220 %\u001b[30m\n",
      "[83,       50] loss: 0.001442254\n",
      "[83,      100] loss: 0.001458461\n",
      "Accuracy on test set: 37 % [1861/5000]\n",
      "\u001b[31mModel parameters and optimizer saved this point with accuracy: 37.220 %\u001b[30m\n",
      "[84,       50] loss: 0.001419546\n",
      "[84,      100] loss: 0.001477772\n",
      "Accuracy on test set: 38 % [1913/5000]\n",
      "\u001b[31mModel parameters and optimizer saved this point with accuracy: 38.260 %\u001b[30m\n",
      "[85,       50] loss: 0.001439256\n",
      "[85,      100] loss: 0.001454568\n",
      "Accuracy on test set: 37 % [1862/5000]\n",
      "\u001b[31mModel parameters and optimizer saved this point with accuracy: 37.240 %\u001b[30m\n",
      "[86,       50] loss: 0.001457700\n",
      "[86,      100] loss: 0.001435763\n",
      "Accuracy on test set: 37 % [1884/5000]\n",
      "\u001b[31mModel parameters and optimizer saved this point with accuracy: 37.680 %\u001b[30m\n",
      "[87,       50] loss: 0.001454999\n",
      "[87,      100] loss: 0.001443256\n",
      "Accuracy on test set: 37 % [1876/5000]\n",
      "\u001b[31mModel parameters and optimizer saved this point with accuracy: 37.520 %\u001b[30m\n",
      "[88,       50] loss: 0.001423228\n",
      "[88,      100] loss: 0.001468195\n",
      "Accuracy on test set: 37 % [1868/5000]\n",
      "\u001b[31mModel parameters and optimizer saved this point with accuracy: 37.360 %\u001b[30m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[89,       50] loss: 0.001437650\n",
      "[89,      100] loss: 0.001451812\n",
      "Accuracy on test set: 37 % [1894/5000]\n",
      "\u001b[31mModel parameters and optimizer saved this point with accuracy: 37.880 %\u001b[30m\n",
      "[90,       50] loss: 0.001436186\n",
      "[90,      100] loss: 0.001456150\n",
      "Accuracy on test set: 38 % [1917/5000]\n",
      "\u001b[31mModel parameters and optimizer saved this point with accuracy: 38.340 %\u001b[30m\n",
      "[91,       50] loss: 0.001435798\n",
      "[91,      100] loss: 0.001460238\n",
      "Accuracy on test set: 37 % [1889/5000]\n",
      "\u001b[31mModel parameters and optimizer saved this point with accuracy: 37.780 %\u001b[30m\n",
      "[92,       50] loss: 0.001422390\n",
      "[92,      100] loss: 0.001466750\n",
      "Accuracy on test set: 37 % [1869/5000]\n",
      "\u001b[31mModel parameters and optimizer saved this point with accuracy: 37.380 %\u001b[30m\n",
      "[93,       50] loss: 0.001430274\n",
      "[93,      100] loss: 0.001453099\n",
      "Accuracy on test set: 37 % [1896/5000]\n",
      "\u001b[31mModel parameters and optimizer saved this point with accuracy: 37.920 %\u001b[30m\n",
      "[94,       50] loss: 0.001431053\n",
      "[94,      100] loss: 0.001457579\n",
      "Accuracy on test set: 37 % [1851/5000]\n",
      "\u001b[31mModel parameters and optimizer saved this point with accuracy: 37.020 %\u001b[30m\n",
      "[95,       50] loss: 0.001446135\n",
      "[95,      100] loss: 0.001437118\n",
      "Accuracy on test set: 38 % [1908/5000]\n",
      "\u001b[31mModel parameters and optimizer saved this point with accuracy: 38.160 %\u001b[30m\n",
      "[96,       50] loss: 0.001422633\n",
      "[96,      100] loss: 0.001448521\n",
      "Accuracy on test set: 37 % [1897/5000]\n",
      "\u001b[31mModel parameters and optimizer saved this point with accuracy: 37.940 %\u001b[30m\n",
      "[97,       50] loss: 0.001429767\n",
      "[97,      100] loss: 0.001452085\n",
      "Accuracy on test set: 37 % [1894/5000]\n",
      "\u001b[31mModel parameters and optimizer saved this point with accuracy: 37.880 %\u001b[30m\n",
      "[98,       50] loss: 0.001453889\n",
      "[98,      100] loss: 0.001441543\n",
      "Accuracy on test set: 36 % [1842/5000]\n",
      "\u001b[31mModel parameters and optimizer saved this point with accuracy: 36.840 %\u001b[30m\n",
      "[99,       50] loss: 0.001425009\n",
      "[99,      100] loss: 0.001449603\n",
      "Accuracy on test set: 37 % [1899/5000]\n",
      "\u001b[31mModel parameters and optimizer saved this point with accuracy: 37.980 %\u001b[30m\n",
      "[100,       50] loss: 0.001424068\n",
      "[100,      100] loss: 0.001447588\n",
      "Accuracy on test set: 37 % [1877/5000]\n",
      "\u001b[31mModel parameters and optimizer saved this point with accuracy: 37.540 %\u001b[30m\n"
     ]
    }
   ],
   "source": [
    "for i in range(epoch):\n",
    "        train(i)\n",
    "        test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's state_dict:\n",
      "conv1.weight \t torch.Size([8, 1, 3, 3])\n",
      "conv1.bias \t torch.Size([8])\n",
      "bn1.weight \t torch.Size([8])\n",
      "bn1.bias \t torch.Size([8])\n",
      "bn1.running_mean \t torch.Size([8])\n",
      "bn1.running_var \t torch.Size([8])\n",
      "bn1.num_batches_tracked \t torch.Size([])\n",
      "conv2.weight \t torch.Size([8, 8, 3, 3])\n",
      "conv2.bias \t torch.Size([8])\n",
      "bn2.weight \t torch.Size([8])\n",
      "bn2.bias \t torch.Size([8])\n",
      "bn2.running_mean \t torch.Size([8])\n",
      "bn2.running_var \t torch.Size([8])\n",
      "bn2.num_batches_tracked \t torch.Size([])\n",
      "fc1.weight \t torch.Size([4, 384])\n",
      "fc1.bias \t torch.Size([4])\n",
      "Optimizer's state_dict:\n",
      "state \t {0: {'step': 10000, 'exp_avg': tensor([[[[ 4.9814e-04,  6.3316e-05,  6.5946e-05],\n",
      "          [-6.7144e-05, -4.3240e-04, -1.1804e-03],\n",
      "          [ 4.3024e-05,  6.0564e-06,  9.4250e-05]]],\n",
      "\n",
      "\n",
      "        [[[ 1.6305e-05,  9.6281e-05, -1.0911e-04],\n",
      "          [-6.4013e-04,  2.8457e-05,  1.2892e-03],\n",
      "          [-1.3430e-04, -3.4323e-05,  1.0287e-04]]],\n",
      "\n",
      "\n",
      "        [[[-1.8946e-04,  2.8487e-05,  2.0980e-04],\n",
      "          [ 9.1549e-05, -2.6520e-05, -1.5664e-04],\n",
      "          [-1.2634e-05,  3.4417e-05, -2.0899e-05]]],\n",
      "\n",
      "\n",
      "        [[[ 3.7796e-04,  2.5963e-06,  9.6747e-04],\n",
      "          [-1.3127e-04,  4.5784e-05,  7.2577e-04],\n",
      "          [ 7.7428e-05, -4.3970e-05,  2.1477e-05]]],\n",
      "\n",
      "\n",
      "        [[[-1.0142e-04,  1.8373e-04, -1.5060e-05],\n",
      "          [ 3.0897e-05,  2.6244e-04, -8.0748e-05],\n",
      "          [ 2.6074e-05, -1.8123e-04, -3.7580e-06]]],\n",
      "\n",
      "\n",
      "        [[[-7.9636e-05,  2.9562e-04, -3.4988e-05],\n",
      "          [-2.2833e-04, -2.9478e-05, -1.3622e-04],\n",
      "          [ 9.0625e-05, -4.0809e-05, -4.0818e-05]]],\n",
      "\n",
      "\n",
      "        [[[ 9.5135e-05, -5.1494e-05, -1.5581e-04],\n",
      "          [-4.5011e-04,  3.5276e-04,  3.2271e-05],\n",
      "          [ 3.0152e-04, -4.0553e-04,  1.0440e-04]]],\n",
      "\n",
      "\n",
      "        [[[-5.8672e-05, -6.8777e-05,  4.0943e-04],\n",
      "          [-1.9261e-04, -5.9147e-05,  2.1688e-05],\n",
      "          [-2.8812e-04, -1.2548e-04, -2.0232e-04]]]], dtype=torch.float64), 'exp_avg_sq': tensor([[[[4.0702e-06, 3.6431e-06, 1.8285e-07],\n",
      "          [4.1662e-06, 5.2613e-06, 2.3897e-06],\n",
      "          [1.4075e-07, 1.7266e-06, 1.6396e-06]]],\n",
      "\n",
      "\n",
      "        [[[2.6016e-07, 2.9859e-07, 3.5290e-07],\n",
      "          [7.1716e-06, 7.0437e-07, 6.8091e-06],\n",
      "          [7.2943e-06, 2.4162e-07, 6.6304e-06]]],\n",
      "\n",
      "\n",
      "        [[[1.1117e-06, 1.4883e-07, 1.3377e-06],\n",
      "          [1.1716e-06, 1.0466e-07, 1.4664e-06],\n",
      "          [1.1391e-07, 1.1662e-07, 1.2885e-07]]],\n",
      "\n",
      "\n",
      "        [[[7.8042e-06, 2.2834e-07, 8.8581e-06],\n",
      "          [8.1872e-06, 5.9147e-07, 8.0868e-06],\n",
      "          [4.2831e-07, 2.1555e-07, 6.2665e-07]]],\n",
      "\n",
      "\n",
      "        [[[1.7499e-07, 1.1183e-07, 9.7485e-08],\n",
      "          [3.5734e-07, 2.2525e-06, 2.5336e-06],\n",
      "          [1.1174e-07, 2.3654e-06, 2.3601e-06]]],\n",
      "\n",
      "\n",
      "        [[[4.4626e-07, 3.2030e-07, 4.6713e-08],\n",
      "          [6.9085e-07, 1.2918e-06, 8.4951e-08],\n",
      "          [3.8354e-07, 5.7047e-07, 7.1137e-08]]],\n",
      "\n",
      "\n",
      "        [[[2.0778e-07, 5.9226e-07, 1.2421e-07],\n",
      "          [2.7037e-06, 2.9394e-06, 3.9766e-07],\n",
      "          [2.4434e-06, 2.3924e-06, 3.3237e-07]]],\n",
      "\n",
      "\n",
      "        [[[1.4168e-06, 1.7004e-07, 1.9267e-06],\n",
      "          [7.2203e-06, 7.6084e-08, 7.4739e-06],\n",
      "          [5.4763e-06, 3.1599e-07, 5.9808e-06]]]], dtype=torch.float64)}, 1: {'step': 10000, 'exp_avg': tensor([ 3.9306e-20, -5.8516e-21, -1.9529e-20, -1.7186e-20,  1.0493e-20,\n",
      "        -2.1259e-21,  3.8758e-20,  2.7796e-20], dtype=torch.float64), 'exp_avg_sq': tensor([3.8888e-38, 4.9937e-38, 8.4880e-39, 6.5632e-38, 1.7945e-38, 5.9922e-39,\n",
      "        2.0008e-38, 3.9813e-38], dtype=torch.float64)}, 2: {'step': 10000, 'exp_avg': tensor([ 1.1318e-05,  2.0730e-05, -3.2150e-05,  2.6290e-05, -3.9540e-05,\n",
      "        -6.8218e-05,  2.5753e-05,  1.4484e-05], dtype=torch.float64), 'exp_avg_sq': tensor([1.3914e-07, 1.3895e-07, 1.3537e-07, 1.5823e-07, 3.2421e-07, 1.4265e-07,\n",
      "        1.1135e-07, 1.3301e-07], dtype=torch.float64)}, 3: {'step': 10000, 'exp_avg': tensor([ 1.9361e-04,  3.7139e-07, -8.2490e-05,  2.5422e-05, -3.2153e-04,\n",
      "        -1.8189e-05,  8.0315e-05, -2.6748e-04], dtype=torch.float64), 'exp_avg_sq': tensor([7.5669e-07, 8.0443e-07, 3.3181e-07, 1.2920e-06, 6.1733e-07, 2.1383e-07,\n",
      "        5.2120e-07, 1.1967e-06], dtype=torch.float64)}, 4: {'step': 10000, 'exp_avg': tensor([[[[ 1.2018e-04,  3.2766e-05,  1.0162e-04],\n",
      "          [ 1.7637e-04,  8.2403e-05,  1.4567e-04],\n",
      "          [-5.9015e-06, -2.9163e-07,  6.3382e-05]],\n",
      "\n",
      "         [[ 3.0023e-05,  1.4023e-05,  5.3713e-06],\n",
      "          [ 8.3753e-06,  5.3634e-05, -1.0624e-05],\n",
      "          [-5.9432e-06, -3.0163e-06,  3.9495e-06]],\n",
      "\n",
      "         [[ 8.3000e-05,  2.4768e-05,  9.9596e-05],\n",
      "          [ 1.0687e-04,  2.9191e-05,  2.4731e-05],\n",
      "          [ 3.0786e-06, -2.2590e-06, -1.0487e-05]],\n",
      "\n",
      "         [[ 4.2541e-06,  6.2505e-05,  2.6460e-05],\n",
      "          [-1.8985e-05,  1.1862e-04, -5.4150e-06],\n",
      "          [-5.5437e-05, -1.3685e-05, -1.5418e-05]],\n",
      "\n",
      "         [[ 3.9600e-05,  2.0447e-05,  2.6185e-05],\n",
      "          [ 9.9378e-06,  2.4529e-06,  1.1699e-06],\n",
      "          [-8.5205e-06, -5.7552e-06,  7.5527e-07]],\n",
      "\n",
      "         [[ 1.8797e-05, -2.8652e-06,  2.1375e-05],\n",
      "          [ 3.7922e-05,  4.1535e-05, -1.7330e-05],\n",
      "          [-1.4875e-05, -6.8423e-06,  5.1389e-05]],\n",
      "\n",
      "         [[ 9.0823e-05,  3.5694e-05, -1.6341e-05],\n",
      "          [ 5.4602e-05,  2.8514e-05,  8.9630e-05],\n",
      "          [ 9.5765e-06, -5.1636e-06,  3.2925e-05]],\n",
      "\n",
      "         [[ 4.3502e-05,  4.3283e-05,  1.2854e-04],\n",
      "          [ 5.1498e-05,  1.4856e-05,  2.9451e-05],\n",
      "          [-1.6097e-05, -2.0732e-05, -2.7250e-05]]],\n",
      "\n",
      "\n",
      "        [[[-1.1179e-04, -1.0621e-05, -1.3588e-04],\n",
      "          [-1.0994e-05, -9.4201e-05, -1.1726e-04],\n",
      "          [-2.8436e-05, -1.1215e-05, -2.3072e-05]],\n",
      "\n",
      "         [[-1.0660e-05,  2.4856e-05,  3.0745e-05],\n",
      "          [-1.0739e-04, -7.5244e-05, -5.1906e-05],\n",
      "          [-1.2398e-05,  2.1556e-05,  3.3097e-06]],\n",
      "\n",
      "         [[-4.7316e-06,  2.4138e-06, -1.7728e-04],\n",
      "          [ 5.8825e-05, -5.4813e-06, -1.2510e-05],\n",
      "          [-1.4328e-05, -1.8311e-05, -2.4063e-05]],\n",
      "\n",
      "         [[-2.9131e-05, -4.0091e-05, -6.9505e-05],\n",
      "          [-1.1800e-04, -6.7289e-05, -4.4038e-05],\n",
      "          [-4.8570e-05,  4.0928e-05,  6.3012e-07]],\n",
      "\n",
      "         [[-4.3031e-05,  4.1030e-05,  2.8827e-06],\n",
      "          [-5.8690e-05,  6.4830e-06, -7.1175e-06],\n",
      "          [ 3.2523e-06, -3.8984e-06, -6.4374e-06]],\n",
      "\n",
      "         [[ 3.7166e-05,  2.7753e-05, -3.3756e-05],\n",
      "          [-1.0404e-04, -3.4238e-05,  5.6359e-05],\n",
      "          [-9.8174e-06,  2.5403e-05, -2.1686e-05]],\n",
      "\n",
      "         [[-8.6715e-05, -3.0279e-05,  2.1528e-05],\n",
      "          [-1.2239e-04,  5.9845e-05, -4.7548e-06],\n",
      "          [-5.4962e-06,  2.0365e-05, -2.1546e-05]],\n",
      "\n",
      "         [[ 6.7303e-05, -6.4674e-05, -1.1049e-04],\n",
      "          [ 3.7657e-05,  1.0012e-06,  3.2061e-05],\n",
      "          [-2.9749e-05, -3.8887e-05, -3.5339e-05]]],\n",
      "\n",
      "\n",
      "        [[[-1.2810e-04, -7.3401e-05, -9.9335e-05],\n",
      "          [ 2.4249e-05,  1.0149e-04, -4.7803e-05],\n",
      "          [ 1.2531e-05, -2.6337e-04,  1.1428e-04]],\n",
      "\n",
      "         [[-3.7173e-05, -5.3336e-05, -1.0498e-04],\n",
      "          [ 7.3402e-05, -1.1535e-04, -6.1582e-05],\n",
      "          [ 1.9657e-04,  1.4671e-05, -1.7531e-04]],\n",
      "\n",
      "         [[-1.1345e-04, -1.1026e-04,  6.6544e-06],\n",
      "          [ 1.3866e-04, -1.6618e-05, -2.3400e-04],\n",
      "          [ 1.2806e-04, -1.1322e-07, -1.5181e-04]],\n",
      "\n",
      "         [[-6.5054e-05, -8.7039e-05, -5.5311e-05],\n",
      "          [ 6.1895e-05, -2.0958e-04, -1.0082e-04],\n",
      "          [ 3.6426e-04, -1.4462e-05, -3.7252e-06]],\n",
      "\n",
      "         [[-3.8922e-06, -3.0631e-05, -1.4431e-05],\n",
      "          [-1.2587e-04,  3.6470e-06,  9.3159e-06],\n",
      "          [ 3.6130e-05,  5.5574e-05, -2.4851e-04]],\n",
      "\n",
      "         [[-6.4664e-05, -7.5924e-05, -3.7804e-06],\n",
      "          [-1.0588e-05,  3.8323e-05, -3.2412e-04],\n",
      "          [ 3.8332e-05, -9.3874e-05,  1.0094e-04]],\n",
      "\n",
      "         [[-7.8528e-05, -2.7105e-05, -2.4316e-05],\n",
      "          [-5.6634e-05, -8.8412e-05, -1.6576e-04],\n",
      "          [ 9.1095e-05,  5.9144e-05,  3.1121e-06]],\n",
      "\n",
      "         [[-8.9884e-05, -1.1653e-04,  1.0659e-04],\n",
      "          [ 9.6644e-05, -3.4738e-05, -4.1448e-04],\n",
      "          [ 1.4971e-04,  4.9494e-05, -1.4351e-04]]],\n",
      "\n",
      "\n",
      "        [[[ 9.2133e-05, -1.5235e-05,  2.1652e-05],\n",
      "          [ 2.0878e-05, -2.2336e-05,  2.8545e-05],\n",
      "          [ 8.3696e-06, -8.0723e-05,  1.3064e-04]],\n",
      "\n",
      "         [[-3.0247e-05, -7.1310e-05,  6.0990e-06],\n",
      "          [ 1.3791e-04, -1.6899e-05, -6.3386e-05],\n",
      "          [ 5.6438e-05, -7.6634e-06, -4.9095e-05]],\n",
      "\n",
      "         [[ 5.0164e-05,  2.5282e-05,  4.3724e-05],\n",
      "          [ 7.4276e-05, -1.7334e-05, -1.4179e-05],\n",
      "          [ 1.0858e-04,  1.3668e-06,  1.5709e-05]],\n",
      "\n",
      "         [[-3.2068e-05,  5.1205e-07, -5.2836e-06],\n",
      "          [ 4.1083e-05, -1.4933e-05, -2.7651e-05],\n",
      "          [ 1.5340e-04,  1.9053e-05, -1.2236e-05]],\n",
      "\n",
      "         [[ 2.7475e-05, -3.7847e-06, -1.8085e-05],\n",
      "          [-1.3637e-05,  7.2442e-05,  1.2505e-06],\n",
      "          [ 8.6516e-06, -2.1606e-06, -9.4955e-05]],\n",
      "\n",
      "         [[-4.5058e-05, -1.3075e-05,  3.5916e-05],\n",
      "          [ 2.2507e-05, -5.4362e-05, -6.3845e-05],\n",
      "          [ 1.9832e-05, -4.0991e-05,  1.0681e-04]],\n",
      "\n",
      "         [[ 6.0092e-06, -3.1810e-05,  4.9985e-06],\n",
      "          [ 5.7420e-05, -1.9281e-05, -1.0421e-05],\n",
      "          [ 2.9748e-06,  6.6861e-05,  2.8987e-05]],\n",
      "\n",
      "         [[-1.3944e-05,  3.1009e-05, -7.1147e-06],\n",
      "          [ 6.2736e-05, -5.9504e-05, -1.0616e-04],\n",
      "          [ 1.4441e-04,  1.2013e-05, -3.0309e-05]]],\n",
      "\n",
      "\n",
      "        [[[ 2.2663e-05,  1.1735e-05,  4.2050e-05],\n",
      "          [-1.7076e-04,  5.7493e-05,  2.7618e-05],\n",
      "          [ 1.6559e-04, -8.4495e-06, -2.1788e-04]],\n",
      "\n",
      "         [[ 2.4904e-05,  3.9669e-06, -2.3219e-05],\n",
      "          [-2.1913e-04,  2.0026e-04,  7.9961e-06],\n",
      "          [ 9.5501e-05,  1.0761e-04,  4.0023e-05]],\n",
      "\n",
      "         [[-4.2395e-05,  1.5110e-05,  5.5148e-05],\n",
      "          [-1.9559e-04,  1.3119e-04, -4.2515e-05],\n",
      "          [-1.4561e-04,  1.4368e-04, -2.2383e-06]],\n",
      "\n",
      "         [[ 3.3874e-06, -1.5518e-05, -1.1108e-05],\n",
      "          [-2.0265e-05,  1.3838e-04, -4.9527e-05],\n",
      "          [-1.2769e-04,  3.1835e-04,  2.0156e-05]],\n",
      "\n",
      "         [[-3.6786e-05, -3.6283e-05, -1.9662e-05],\n",
      "          [-9.3106e-06, -1.4111e-04,  1.2180e-04],\n",
      "          [ 2.2549e-04, -9.3685e-06,  7.7163e-05]],\n",
      "\n",
      "         [[-2.7242e-05, -1.1086e-05, -8.3165e-08],\n",
      "          [ 2.2475e-04, -5.5860e-06,  6.2030e-05],\n",
      "          [-7.1098e-05,  4.2811e-05, -4.1564e-05]],\n",
      "\n",
      "         [[-3.4268e-06, -2.0269e-05,  3.5916e-05],\n",
      "          [ 8.8557e-05, -2.2609e-05,  6.0069e-05],\n",
      "          [-7.0562e-05,  1.3393e-05,  1.2437e-04]],\n",
      "\n",
      "         [[-5.3938e-05,  5.7281e-05,  1.3129e-05],\n",
      "          [-1.2502e-05,  1.3108e-04, -5.0705e-05],\n",
      "          [-1.9031e-04,  1.7633e-04,  4.2687e-05]]],\n",
      "\n",
      "\n",
      "        [[[ 2.8800e-05, -5.8732e-05,  1.3226e-05],\n",
      "          [ 7.9941e-05, -5.6801e-05, -5.2215e-05],\n",
      "          [-1.4431e-06, -5.1637e-05,  5.9004e-05]],\n",
      "\n",
      "         [[-1.8143e-05,  1.6601e-05, -3.1680e-05],\n",
      "          [ 9.2341e-05,  5.1993e-05,  5.2703e-05],\n",
      "          [ 6.4186e-05,  1.7009e-05, -8.8926e-05]],\n",
      "\n",
      "         [[ 5.4168e-05, -4.6389e-05, -7.6837e-05],\n",
      "          [ 1.7396e-04,  2.9267e-05, -7.9290e-05],\n",
      "          [ 9.0551e-05,  2.0063e-06,  7.3439e-06]],\n",
      "\n",
      "         [[ 2.4048e-05, -3.0816e-05,  5.6358e-05],\n",
      "          [ 8.3991e-05, -2.5089e-06,  1.1335e-04],\n",
      "          [ 1.0914e-04,  1.0281e-05, -5.9933e-05]],\n",
      "\n",
      "         [[-2.2877e-05, -1.3879e-06,  4.1372e-06],\n",
      "          [ 3.0689e-05,  1.1733e-04, -7.9299e-05],\n",
      "          [ 3.8679e-05,  1.4524e-05, -6.0979e-05]],\n",
      "\n",
      "         [[ 1.4632e-06,  1.4332e-05, -1.0680e-04],\n",
      "          [ 5.1287e-05, -1.7002e-05,  1.4911e-05],\n",
      "          [ 1.2079e-05, -7.5984e-06,  7.1333e-05]],\n",
      "\n",
      "         [[ 8.9950e-06,  5.9617e-05, -3.3826e-05],\n",
      "          [-6.9814e-06, -1.6271e-05,  1.6139e-05],\n",
      "          [ 3.1225e-05,  1.0650e-04,  8.9050e-06]],\n",
      "\n",
      "         [[ 2.2993e-05, -6.6546e-07, -1.0055e-04],\n",
      "          [ 1.6079e-04,  1.6707e-05, -1.5995e-04],\n",
      "          [ 8.0828e-05,  1.5800e-05,  3.6670e-05]]],\n",
      "\n",
      "\n",
      "        [[[-5.1754e-05, -6.4069e-05, -1.7799e-05],\n",
      "          [-2.4456e-05, -1.1950e-04,  4.0753e-05],\n",
      "          [-2.6052e-05, -1.3053e-05,  5.5063e-05]],\n",
      "\n",
      "         [[-2.0923e-05, -3.1764e-05, -1.6211e-05],\n",
      "          [ 7.8801e-06, -5.3443e-05, -1.0818e-04],\n",
      "          [-5.4459e-07, -1.7258e-05, -2.1359e-05]],\n",
      "\n",
      "         [[-2.3936e-05, -6.1461e-05, -8.1445e-05],\n",
      "          [-3.8058e-05, -3.3230e-05, -6.7755e-05],\n",
      "          [-2.4137e-05, -2.3633e-06,  7.7229e-06]],\n",
      "\n",
      "         [[ 9.5527e-06, -1.2711e-05, -7.5425e-05],\n",
      "          [ 2.6644e-05, -1.9741e-05, -1.4729e-04],\n",
      "          [ 3.8552e-06, -3.0235e-05, -2.2578e-05]],\n",
      "\n",
      "         [[ 9.4083e-06, -1.8930e-05, -1.7065e-05],\n",
      "          [ 1.3900e-05, -7.7952e-05, -4.4798e-05],\n",
      "          [-7.9119e-06, -1.4473e-05, -1.1294e-05]],\n",
      "\n",
      "         [[-1.0957e-05, -2.0088e-05, -7.6241e-05],\n",
      "          [-1.8486e-05, -4.2542e-05,  1.2441e-05],\n",
      "          [-1.0918e-06, -2.6113e-05, -2.4863e-05]],\n",
      "\n",
      "         [[-2.7086e-06, -7.0464e-05, -2.7113e-05],\n",
      "          [ 9.4335e-06, -3.8793e-05, -3.8422e-05],\n",
      "          [ 1.4594e-05, -3.6998e-05, -2.7988e-05]],\n",
      "\n",
      "         [[-2.5738e-05, -5.6432e-05, -1.2474e-04],\n",
      "          [-7.3916e-05, -6.1781e-05, -8.0881e-05],\n",
      "          [-1.2438e-05,  2.1815e-06,  4.4446e-06]]],\n",
      "\n",
      "\n",
      "        [[[-1.6739e-04,  1.7880e-06, -1.0545e-04],\n",
      "          [-2.6246e-04,  1.4550e-04,  2.4645e-04],\n",
      "          [ 3.5378e-05,  2.9503e-05, -9.3964e-06]],\n",
      "\n",
      "         [[ 4.7901e-05, -1.1916e-04, -2.5869e-05],\n",
      "          [ 6.5924e-06, -2.3305e-04, -2.1545e-04],\n",
      "          [-8.2979e-05,  2.8973e-05, -4.1359e-07]],\n",
      "\n",
      "         [[-1.2163e-04, -1.0612e-04, -3.9815e-05],\n",
      "          [ 2.7916e-05, -1.2830e-04,  1.5467e-04],\n",
      "          [-1.4975e-05,  3.3225e-05,  9.1826e-06]],\n",
      "\n",
      "         [[-6.0723e-05,  1.0341e-04, -2.4374e-04],\n",
      "          [-7.4831e-05,  1.1088e-04, -3.8709e-04],\n",
      "          [-1.3367e-04,  1.5084e-05, -6.7510e-05]],\n",
      "\n",
      "         [[ 7.9702e-06,  3.6438e-05, -1.1737e-04],\n",
      "          [ 1.6206e-06, -2.2711e-04, -6.9102e-05],\n",
      "          [-2.8335e-05, -7.9320e-06,  6.0116e-05]],\n",
      "\n",
      "         [[ 2.4039e-06, -1.8532e-04, -1.6500e-08],\n",
      "          [-1.2680e-04,  5.1769e-05,  6.1932e-05],\n",
      "          [-2.3888e-05, -1.9198e-05, -9.0226e-05]],\n",
      "\n",
      "         [[ 6.2544e-06, -1.1880e-04,  8.7679e-06],\n",
      "          [ 4.9605e-05, -3.1670e-05, -1.7796e-04],\n",
      "          [-1.7735e-05, -7.4286e-07, -2.7482e-06]],\n",
      "\n",
      "         [[-3.3929e-05, -2.7605e-04,  1.8428e-04],\n",
      "          [ 1.1313e-04, -1.8464e-04,  1.0040e-04],\n",
      "          [ 1.0808e-05, -9.7465e-05,  1.4867e-05]]]], dtype=torch.float64), 'exp_avg_sq': tensor([[[[1.7645e-07, 7.8240e-08, 2.2197e-07],\n",
      "          [2.1338e-07, 3.7388e-08, 7.9753e-08],\n",
      "          [2.0466e-08, 1.1588e-08, 1.8392e-07]],\n",
      "\n",
      "         [[1.2735e-07, 3.6847e-07, 2.1343e-07],\n",
      "          [5.4426e-08, 9.9722e-08, 6.3479e-08],\n",
      "          [5.9473e-08, 2.2823e-08, 9.5808e-08]],\n",
      "\n",
      "         [[1.2131e-07, 1.1763e-07, 1.3864e-07],\n",
      "          [5.2626e-08, 7.7426e-08, 4.6842e-08],\n",
      "          [1.0624e-08, 1.2240e-08, 5.5919e-09]],\n",
      "\n",
      "         [[5.9971e-08, 1.3764e-07, 8.8785e-08],\n",
      "          [5.9028e-08, 3.5410e-07, 1.6997e-07],\n",
      "          [5.5491e-08, 2.9072e-08, 4.0987e-08]],\n",
      "\n",
      "         [[5.8343e-08, 3.7620e-08, 8.5287e-08],\n",
      "          [1.3162e-07, 7.7469e-08, 6.8190e-08],\n",
      "          [4.7772e-08, 2.1812e-08, 1.4306e-07]],\n",
      "\n",
      "         [[1.4942e-07, 1.1835e-07, 9.8484e-08],\n",
      "          [4.1766e-08, 2.3764e-08, 9.6343e-08],\n",
      "          [2.2848e-08, 1.9025e-08, 1.1260e-07]],\n",
      "\n",
      "         [[1.2203e-07, 7.2853e-08, 9.0258e-08],\n",
      "          [8.5953e-08, 4.7277e-08, 1.4527e-07],\n",
      "          [1.2605e-07, 1.8349e-08, 5.1809e-08]],\n",
      "\n",
      "         [[1.5087e-07, 2.9067e-07, 1.9115e-07],\n",
      "          [4.0608e-08, 2.5046e-07, 1.1908e-07],\n",
      "          [3.9314e-08, 4.3200e-08, 3.3538e-08]]],\n",
      "\n",
      "\n",
      "        [[[1.5827e-07, 2.3566e-07, 9.7511e-08],\n",
      "          [8.5188e-08, 7.8644e-08, 1.4467e-07],\n",
      "          [5.5612e-09, 1.0643e-08, 4.6204e-09]],\n",
      "\n",
      "         [[2.5033e-07, 7.2538e-08, 9.7021e-08],\n",
      "          [1.1984e-07, 1.7863e-07, 1.0951e-07],\n",
      "          [5.7769e-08, 3.3549e-08, 4.6371e-08]],\n",
      "\n",
      "         [[7.9362e-08, 8.7565e-08, 6.8945e-08],\n",
      "          [1.2564e-07, 3.1367e-08, 3.7008e-08],\n",
      "          [2.6788e-09, 1.2923e-08, 8.0812e-09]],\n",
      "\n",
      "         [[1.1375e-07, 2.9399e-08, 8.0472e-08],\n",
      "          [3.9632e-07, 1.2665e-07, 2.1986e-07],\n",
      "          [2.8050e-08, 1.7348e-07, 7.6011e-08]],\n",
      "\n",
      "         [[4.9435e-08, 7.0189e-08, 2.0155e-08],\n",
      "          [4.6107e-08, 8.4250e-08, 1.0258e-07],\n",
      "          [8.3760e-08, 1.4368e-08, 4.2488e-08]],\n",
      "\n",
      "         [[2.8296e-08, 5.9317e-08, 8.2157e-08],\n",
      "          [8.7754e-08, 3.6760e-08, 9.6977e-08],\n",
      "          [4.0523e-09, 2.3599e-08, 3.5500e-09]],\n",
      "\n",
      "         [[5.1066e-08, 6.9884e-08, 9.6951e-08],\n",
      "          [9.3327e-08, 1.2993e-07, 4.2817e-08],\n",
      "          [1.3007e-08, 1.2351e-08, 5.6811e-09]],\n",
      "\n",
      "         [[3.0032e-07, 9.0616e-08, 1.7192e-07],\n",
      "          [2.5009e-07, 7.6497e-08, 7.5542e-08],\n",
      "          [7.9646e-09, 1.0849e-07, 2.2475e-08]]],\n",
      "\n",
      "\n",
      "        [[[1.4147e-07, 1.6099e-07, 1.6324e-07],\n",
      "          [1.1847e-06, 1.5805e-06, 7.7045e-08],\n",
      "          [1.2614e-08, 8.6041e-07, 7.0690e-07]],\n",
      "\n",
      "         [[2.6263e-07, 2.5177e-07, 2.3411e-07],\n",
      "          [1.3861e-06, 1.5773e-07, 1.4268e-06],\n",
      "          [5.4325e-07, 3.5192e-07, 3.8759e-07]],\n",
      "\n",
      "         [[1.2976e-07, 1.5469e-07, 1.5987e-07],\n",
      "          [4.8645e-07, 4.0989e-07, 3.7425e-07],\n",
      "          [7.3837e-07, 6.4730e-09, 5.8986e-07]],\n",
      "\n",
      "         [[1.1123e-07, 1.0823e-07, 1.0581e-07],\n",
      "          [5.0453e-07, 3.9457e-07, 5.4322e-07],\n",
      "          [2.1664e-06, 3.6896e-08, 1.8857e-06]],\n",
      "\n",
      "         [[4.1169e-08, 6.6170e-08, 6.0045e-08],\n",
      "          [4.3265e-07, 5.6179e-07, 1.0682e-07],\n",
      "          [1.4570e-07, 6.1688e-07, 5.1704e-07]],\n",
      "\n",
      "         [[1.2059e-07, 1.1452e-07, 9.6367e-08],\n",
      "          [8.9891e-08, 5.4538e-07, 4.7449e-07],\n",
      "          [4.2281e-08, 3.6313e-07, 3.0553e-07]],\n",
      "\n",
      "         [[9.3313e-08, 1.1886e-07, 7.0081e-08],\n",
      "          [8.0305e-08, 7.6740e-07, 6.5513e-07],\n",
      "          [5.5403e-07, 6.2200e-07, 1.0063e-07]],\n",
      "\n",
      "         [[2.1225e-07, 2.8710e-07, 3.2324e-07],\n",
      "          [1.3999e-06, 2.1016e-07, 1.5249e-06],\n",
      "          [1.4430e-06, 2.9908e-08, 1.2329e-06]]],\n",
      "\n",
      "\n",
      "        [[[4.2547e-08, 5.1781e-09, 1.2860e-08],\n",
      "          [1.4934e-07, 3.5988e-07, 4.5441e-08],\n",
      "          [5.9468e-09, 2.5794e-07, 2.3239e-07]],\n",
      "\n",
      "         [[1.0392e-08, 2.7274e-08, 6.5895e-08],\n",
      "          [3.9016e-07, 3.0968e-08, 2.6919e-07],\n",
      "          [1.6095e-07, 8.1213e-08, 1.1088e-07]],\n",
      "\n",
      "         [[1.5297e-08, 1.3538e-08, 2.2860e-08],\n",
      "          [1.4346e-07, 1.2399e-07, 1.4476e-07],\n",
      "          [2.2340e-07, 3.0850e-09, 1.3430e-07]],\n",
      "\n",
      "         [[4.6545e-09, 1.0031e-08, 2.7175e-08],\n",
      "          [1.7721e-07, 4.4185e-08, 1.9428e-07],\n",
      "          [6.4334e-07, 1.7325e-08, 3.8291e-07]],\n",
      "\n",
      "         [[1.1993e-08, 3.0400e-09, 6.4226e-09],\n",
      "          [8.5041e-08, 1.1848e-07, 1.9051e-08],\n",
      "          [4.2063e-08, 1.2574e-07, 1.6887e-07]],\n",
      "\n",
      "         [[1.2703e-08, 2.8908e-08, 2.2433e-08],\n",
      "          [1.7847e-08, 1.1484e-07, 1.3834e-07],\n",
      "          [1.2986e-08, 1.3039e-07, 1.0698e-07]],\n",
      "\n",
      "         [[4.6101e-09, 3.6042e-08, 1.4314e-08],\n",
      "          [1.1868e-08, 1.8218e-07, 1.8879e-07],\n",
      "          [1.4245e-07, 2.1574e-07, 3.7002e-08]],\n",
      "\n",
      "         [[1.1655e-08, 3.7089e-08, 7.3440e-08],\n",
      "          [5.3790e-07, 3.2625e-08, 5.4602e-07],\n",
      "          [4.1741e-07, 1.1392e-08, 2.5936e-07]]],\n",
      "\n",
      "\n",
      "        [[[5.4790e-08, 7.1523e-08, 1.4714e-07],\n",
      "          [1.0414e-06, 9.6628e-07, 1.0368e-06],\n",
      "          [5.8433e-07, 1.4599e-08, 7.2364e-07]],\n",
      "\n",
      "         [[1.2564e-07, 1.9798e-07, 2.1984e-07],\n",
      "          [9.5077e-07, 1.0377e-06, 1.1719e-07],\n",
      "          [3.3555e-07, 3.2759e-07, 2.7326e-07]],\n",
      "\n",
      "         [[6.6211e-08, 9.9012e-08, 9.1646e-08],\n",
      "          [4.3006e-07, 4.3785e-07, 3.1133e-07],\n",
      "          [3.4347e-07, 3.6178e-07, 9.9612e-09]],\n",
      "\n",
      "         [[4.0614e-08, 8.7883e-08, 5.4566e-08],\n",
      "          [5.5163e-07, 5.9498e-07, 2.0065e-07],\n",
      "          [1.5283e-06, 1.4611e-06, 3.6943e-08]],\n",
      "\n",
      "         [[4.9341e-08, 3.7057e-08, 5.2468e-08],\n",
      "          [3.8598e-07, 3.4083e-07, 2.8266e-07],\n",
      "          [4.2623e-07, 1.0654e-07, 4.8048e-07]],\n",
      "\n",
      "         [[8.0427e-08, 1.0682e-07, 3.8922e-08],\n",
      "          [3.7174e-07, 7.2453e-08, 4.2422e-07],\n",
      "          [2.6731e-07, 2.8072e-08, 2.9819e-07]],\n",
      "\n",
      "         [[8.1243e-08, 4.2548e-08, 5.9274e-08],\n",
      "          [6.1449e-07, 8.2413e-08, 6.2591e-07],\n",
      "          [4.5465e-07, 3.9542e-07, 4.1473e-07]],\n",
      "\n",
      "         [[1.4321e-07, 2.3171e-07, 1.7672e-07],\n",
      "          [1.2140e-06, 1.3220e-06, 1.9578e-07],\n",
      "          [7.4046e-07, 7.2808e-07, 2.5179e-08]]],\n",
      "\n",
      "\n",
      "        [[[2.3244e-07, 2.1557e-07, 6.9966e-09],\n",
      "          [1.5464e-07, 2.7108e-07, 1.5566e-07],\n",
      "          [5.2584e-09, 1.2683e-07, 1.2269e-07]],\n",
      "\n",
      "         [[2.4147e-07, 1.1935e-08, 4.0906e-07],\n",
      "          [4.4962e-07, 1.0378e-07, 4.2561e-07],\n",
      "          [9.4926e-08, 6.7644e-08, 1.1600e-07]],\n",
      "\n",
      "         [[8.1118e-08, 8.1307e-08, 9.3589e-08],\n",
      "          [3.0022e-07, 6.8682e-08, 2.7144e-07],\n",
      "          [1.2093e-07, 3.0442e-09, 8.5224e-08]],\n",
      "\n",
      "         [[9.9186e-08, 2.3703e-08, 1.6615e-07],\n",
      "          [6.8433e-07, 2.8589e-08, 1.0475e-06],\n",
      "          [3.3942e-07, 1.5361e-08, 3.9975e-07]],\n",
      "\n",
      "         [[8.0401e-08, 7.1160e-08, 2.6957e-09],\n",
      "          [1.1563e-07, 2.2641e-07, 1.4330e-07],\n",
      "          [2.3361e-08, 1.1704e-07, 8.6484e-08]],\n",
      "\n",
      "         [[1.0406e-08, 1.7226e-07, 1.1308e-07],\n",
      "          [2.1916e-08, 2.5542e-07, 1.7068e-07],\n",
      "          [1.0783e-08, 5.1385e-08, 5.6216e-08]],\n",
      "\n",
      "         [[3.7000e-09, 2.3099e-07, 1.4355e-07],\n",
      "          [1.4489e-07, 2.5834e-07, 1.6423e-07],\n",
      "          [7.4494e-08, 1.0855e-07, 2.2108e-08]],\n",
      "\n",
      "         [[3.0411e-07, 1.4564e-08, 4.0413e-07],\n",
      "          [7.7295e-07, 2.2492e-08, 7.2232e-07],\n",
      "          [2.6456e-07, 1.1360e-08, 1.7244e-07]]],\n",
      "\n",
      "\n",
      "        [[[1.5543e-07, 1.1460e-07, 1.0969e-08],\n",
      "          [2.9770e-08, 1.3337e-07, 9.5594e-08],\n",
      "          [5.3044e-09, 6.5051e-08, 6.1711e-08]],\n",
      "\n",
      "         [[1.4204e-07, 1.4887e-08, 1.7796e-07],\n",
      "          [5.2773e-08, 1.3152e-07, 9.2822e-08],\n",
      "          [2.0693e-08, 9.6778e-09, 1.3597e-08]],\n",
      "\n",
      "         [[8.9500e-08, 3.9204e-08, 5.1395e-08],\n",
      "          [6.4091e-08, 1.8493e-08, 1.0244e-07],\n",
      "          [3.5223e-09, 9.2138e-09, 4.2396e-08]],\n",
      "\n",
      "         [[6.0361e-08, 1.6134e-08, 6.1758e-08],\n",
      "          [2.0292e-07, 3.2287e-08, 2.5815e-07],\n",
      "          [1.9417e-08, 3.8682e-08, 1.3654e-08]],\n",
      "\n",
      "         [[3.7625e-08, 3.7644e-08, 3.8949e-09],\n",
      "          [3.1549e-08, 8.6898e-08, 6.7194e-08],\n",
      "          [2.1272e-08, 4.7171e-09, 1.8805e-08]],\n",
      "\n",
      "         [[1.0442e-08, 7.2653e-08, 6.4975e-08],\n",
      "          [2.2646e-08, 6.1560e-08, 6.9432e-08],\n",
      "          [8.0937e-09, 2.7372e-08, 1.8476e-08]],\n",
      "\n",
      "         [[6.5232e-09, 8.6664e-08, 7.9204e-08],\n",
      "          [6.6455e-08, 5.7226e-08, 2.8307e-08],\n",
      "          [1.4897e-08, 1.3878e-08, 5.4084e-09]],\n",
      "\n",
      "         [[1.5953e-07, 1.9438e-08, 1.8791e-07],\n",
      "          [1.2342e-07, 2.9758e-08, 2.5069e-07],\n",
      "          [9.1975e-09, 5.5565e-08, 6.3438e-08]]],\n",
      "\n",
      "\n",
      "        [[[1.2577e-06, 2.5518e-08, 1.4477e-06],\n",
      "          [1.6038e-06, 7.8112e-07, 1.3366e-06],\n",
      "          [4.0646e-07, 2.0009e-07, 4.3516e-07]],\n",
      "\n",
      "         [[3.9850e-08, 1.5876e-06, 1.0872e-06],\n",
      "          [4.5920e-07, 7.2920e-07, 7.9281e-07],\n",
      "          [3.4017e-07, 2.9945e-07, 2.8221e-07]],\n",
      "\n",
      "         [[4.0672e-07, 4.9481e-07, 6.0561e-07],\n",
      "          [3.7118e-07, 6.8695e-07, 5.3644e-07],\n",
      "          [6.7320e-08, 2.5453e-07, 1.2223e-07]],\n",
      "\n",
      "         [[8.2611e-08, 7.0170e-07, 5.6010e-07],\n",
      "          [1.8475e-07, 2.4379e-06, 2.0768e-06],\n",
      "          [3.1149e-07, 9.2706e-07, 3.0278e-07]],\n",
      "\n",
      "         [[2.9182e-07, 1.0240e-08, 4.0718e-07],\n",
      "          [8.8329e-07, 5.0925e-07, 7.1241e-07],\n",
      "          [4.1612e-07, 1.1130e-07, 4.4923e-07]],\n",
      "\n",
      "         [[6.8655e-07, 5.1324e-07, 5.4073e-07],\n",
      "          [5.7582e-07, 3.6768e-07, 4.9128e-07],\n",
      "          [2.5249e-07, 1.3718e-07, 2.2328e-07]],\n",
      "\n",
      "         [[8.5185e-07, 5.8815e-07, 7.3776e-07],\n",
      "          [7.2209e-07, 2.7758e-07, 8.2633e-07],\n",
      "          [4.0313e-07, 1.2700e-07, 3.9244e-07]],\n",
      "\n",
      "         [[4.2882e-08, 1.9872e-06, 1.3547e-06],\n",
      "          [2.6207e-07, 1.6549e-06, 1.5872e-06],\n",
      "          [1.8402e-07, 6.1619e-07, 2.7357e-07]]]], dtype=torch.float64)}, 5: {'step': 10000, 'exp_avg': tensor([-1.1722e-18,  2.6425e-20,  2.1630e-18,  2.3593e-19,  1.8216e-18,\n",
      "         4.3502e-19, -3.1351e-20,  8.7734e-19], dtype=torch.float64), 'exp_avg_sq': tensor([8.8632e-35, 2.1121e-36, 6.7092e-35, 2.2797e-36, 1.8284e-35, 4.0939e-36,\n",
      "        2.8913e-36, 2.9784e-35], dtype=torch.float64)}, 6: {'step': 10000, 'exp_avg': tensor([-1.9830e-04, -9.2323e-05,  6.0242e-05,  4.1192e-05,  8.2298e-06,\n",
      "         5.5980e-05,  3.7157e-05,  1.1452e-04], dtype=torch.float64), 'exp_avg_sq': tensor([5.8399e-06, 2.1137e-07, 9.8190e-07, 1.7976e-07, 1.7868e-07, 1.3557e-07,\n",
      "        2.3637e-07, 4.2604e-07], dtype=torch.float64)}, 7: {'step': 10000, 'exp_avg': tensor([-2.7145e-04,  1.8589e-05,  2.0442e-04,  1.9346e-04,  1.3711e-04,\n",
      "         6.6092e-05,  1.7479e-04,  2.0886e-04], dtype=torch.float64), 'exp_avg_sq': tensor([1.1788e-05, 5.2133e-07, 6.6461e-06, 3.0276e-07, 2.1453e-06, 7.0927e-07,\n",
      "        6.0761e-07, 2.3158e-06], dtype=torch.float64)}, 8: {'step': 10000, 'exp_avg': tensor([[ 2.5797e-05,  2.8106e-05,  1.5663e-05,  ..., -3.2188e-05,\n",
      "          3.6077e-05, -1.3144e-05],\n",
      "        [ 5.6579e-05, -1.1469e-05,  1.0354e-07,  ..., -1.8954e-05,\n",
      "         -1.4963e-05,  4.7782e-06],\n",
      "        [-5.6058e-05, -2.8804e-05, -1.6928e-05,  ...,  2.6406e-05,\n",
      "         -4.3051e-06, -4.2295e-06],\n",
      "        [-1.2880e-05,  1.6492e-06,  6.6537e-06,  ...,  2.3022e-05,\n",
      "          6.0829e-06,  6.4058e-06]], dtype=torch.float64), 'exp_avg_sq': tensor([[5.3799e-08, 8.4459e-09, 1.7646e-09,  ..., 5.7382e-08, 1.0261e-08,\n",
      "         3.8049e-09],\n",
      "        [5.5790e-08, 9.6219e-09, 9.6600e-09,  ..., 2.4389e-08, 1.9858e-08,\n",
      "         2.8031e-09],\n",
      "        [1.5654e-08, 8.9770e-09, 1.0572e-08,  ..., 2.1590e-08, 3.8619e-09,\n",
      "         7.1651e-09],\n",
      "        [2.8627e-08, 1.6328e-09, 1.0455e-08,  ..., 1.3807e-08, 3.8583e-09,\n",
      "         6.4115e-10]], dtype=torch.float64)}, 9: {'step': 10000, 'exp_avg': tensor([-3.7426e-05,  1.2084e-04, -8.8614e-05,  1.4729e-05],\n",
      "       dtype=torch.float64), 'exp_avg_sq': tensor([6.2623e-07, 6.0341e-07, 6.1384e-07, 6.3997e-07], dtype=torch.float64)}}\n",
      "param_groups \t [{'lr': 0.001, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}]\n"
     ]
    }
   ],
   "source": [
    "PATH1='best-model-parameters.pt'\n",
    "model_best = BNN_P1()\n",
    "model_best.load_state_dict(torch.load(PATH1))\n",
    "model_best.eval()\n",
    "print(\"Model's state_dict:\")\n",
    "for param_tensor in model.state_dict():\n",
    "    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())\n",
    "\n",
    "PATH2='best-optimizer-parameters.pt'\n",
    "optimizer_best = optim.Adam(model.parameters(),lr=0.001)\n",
    "optimizer_best.load_state_dict(torch.load(PATH2))   \n",
    "    \n",
    "# Print optimizer's state_dict\n",
    "print(\"Optimizer's state_dict:\")\n",
    "for var_name in optimizer_best.state_dict():\n",
    "    print(var_name, \"\\t\", optimizer_best.state_dict()[var_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[2.5442e-01],\n",
      "         [4.4016e-04],\n",
      "         [2.9115e-01],\n",
      "         [5.0585e-01]],\n",
      "\n",
      "        [[3.9218e-01],\n",
      "         [1.6079e-02],\n",
      "         [4.3464e-02],\n",
      "         [2.9202e-01]],\n",
      "\n",
      "        [[3.2774e-01],\n",
      "         [4.5501e-01],\n",
      "         [2.7436e-01],\n",
      "         [2.6855e-02]],\n",
      "\n",
      "        [[2.9853e-01],\n",
      "         [1.5085e-01],\n",
      "         [4.2238e-01],\n",
      "         [2.1560e-01]],\n",
      "\n",
      "        [[6.6012e-04],\n",
      "         [3.3648e-02],\n",
      "         [7.3067e-01],\n",
      "         [2.9832e-01]],\n",
      "\n",
      "        [[1.3166e-02],\n",
      "         [7.6078e-01],\n",
      "         [2.4259e-01],\n",
      "         [3.9006e-02]],\n",
      "\n",
      "        [[3.8646e-01],\n",
      "         [4.6956e-02],\n",
      "         [4.6325e-01],\n",
      "         [6.7012e-02]],\n",
      "\n",
      "        [[3.8266e-01],\n",
      "         [7.1561e-01],\n",
      "         [4.3650e-02],\n",
      "         [4.9273e-04]],\n",
      "\n",
      "        [[6.0753e-01],\n",
      "         [5.2658e-02],\n",
      "         [2.5016e-01],\n",
      "         [7.7293e-02]],\n",
      "\n",
      "        [[9.1838e-03],\n",
      "         [2.5377e-01],\n",
      "         [5.0475e-01],\n",
      "         [6.5296e-02]],\n",
      "\n",
      "        [[3.7235e-01],\n",
      "         [3.9873e-01],\n",
      "         [2.8302e-02],\n",
      "         [1.4725e-01]],\n",
      "\n",
      "        [[3.1951e-02],\n",
      "         [5.6077e-03],\n",
      "         [7.2283e-01],\n",
      "         [2.5141e-01]],\n",
      "\n",
      "        [[1.0976e-01],\n",
      "         [3.4400e-01],\n",
      "         [1.1518e-02],\n",
      "         [5.9420e-01]],\n",
      "\n",
      "        [[3.6733e-03],\n",
      "         [4.4051e-02],\n",
      "         [1.3164e-02],\n",
      "         [9.5046e-01]],\n",
      "\n",
      "        [[6.0433e-02],\n",
      "         [2.5774e-02],\n",
      "         [3.8768e-01],\n",
      "         [5.5607e-01]],\n",
      "\n",
      "        [[9.1957e-01],\n",
      "         [1.4857e-02],\n",
      "         [5.2919e-02],\n",
      "         [5.2023e-03]],\n",
      "\n",
      "        [[1.2284e-02],\n",
      "         [5.6664e-01],\n",
      "         [4.2183e-01],\n",
      "         [3.1124e-02]],\n",
      "\n",
      "        [[5.0129e-01],\n",
      "         [3.3786e-05],\n",
      "         [2.4711e-01],\n",
      "         [1.7512e-01]],\n",
      "\n",
      "        [[3.5633e-02],\n",
      "         [4.3152e-01],\n",
      "         [4.5521e-01],\n",
      "         [3.6954e-02]],\n",
      "\n",
      "        [[5.5627e-01],\n",
      "         [2.7177e-01],\n",
      "         [2.1566e-01],\n",
      "         [6.2955e-03]],\n",
      "\n",
      "        [[9.8967e-04],\n",
      "         [6.1630e-01],\n",
      "         [1.8357e-01],\n",
      "         [2.6104e-01]],\n",
      "\n",
      "        [[4.8407e-01],\n",
      "         [3.5429e-01],\n",
      "         [1.4086e-01],\n",
      "         [6.0921e-02]],\n",
      "\n",
      "        [[6.6164e-01],\n",
      "         [1.5821e-01],\n",
      "         [1.2268e-04],\n",
      "         [2.2444e-01]],\n",
      "\n",
      "        [[3.4445e-01],\n",
      "         [5.1175e-05],\n",
      "         [1.9888e-03],\n",
      "         [7.1702e-01]],\n",
      "\n",
      "        [[1.2336e-01],\n",
      "         [8.2480e-03],\n",
      "         [7.8622e-01],\n",
      "         [2.8793e-02]],\n",
      "\n",
      "        [[5.9864e-01],\n",
      "         [2.5859e-01],\n",
      "         [8.9285e-03],\n",
      "         [9.3677e-02]],\n",
      "\n",
      "        [[2.4873e-01],\n",
      "         [3.3256e-01],\n",
      "         [4.1343e-01],\n",
      "         [1.8105e-01]],\n",
      "\n",
      "        [[6.0372e-02],\n",
      "         [2.4379e-01],\n",
      "         [7.5192e-01],\n",
      "         [3.2091e-02]],\n",
      "\n",
      "        [[9.1067e-02],\n",
      "         [5.0697e-01],\n",
      "         [2.4281e-01],\n",
      "         [9.8934e-02]],\n",
      "\n",
      "        [[3.8620e-01],\n",
      "         [4.0814e-02],\n",
      "         [3.7007e-01],\n",
      "         [2.4318e-01]],\n",
      "\n",
      "        [[1.0954e-01],\n",
      "         [7.5101e-02],\n",
      "         [2.6004e-01],\n",
      "         [5.2071e-01]],\n",
      "\n",
      "        [[5.1575e-02],\n",
      "         [1.0635e-01],\n",
      "         [2.4865e-01],\n",
      "         [4.5354e-01]],\n",
      "\n",
      "        [[1.6885e-02],\n",
      "         [5.0493e-01],\n",
      "         [2.5084e-01],\n",
      "         [2.4875e-01]],\n",
      "\n",
      "        [[2.2363e-01],\n",
      "         [4.3303e-01],\n",
      "         [7.0320e-02],\n",
      "         [2.9755e-01]],\n",
      "\n",
      "        [[2.5540e-03],\n",
      "         [8.1650e-01],\n",
      "         [2.6485e-02],\n",
      "         [8.5850e-02]],\n",
      "\n",
      "        [[9.0755e-03],\n",
      "         [3.0162e-01],\n",
      "         [7.0457e-01],\n",
      "         [2.3924e-02]],\n",
      "\n",
      "        [[3.0624e-01],\n",
      "         [3.4422e-01],\n",
      "         [8.9627e-02],\n",
      "         [3.2807e-01]],\n",
      "\n",
      "        [[3.6502e-03],\n",
      "         [3.7429e-03],\n",
      "         [2.7921e-01],\n",
      "         [7.2909e-01]],\n",
      "\n",
      "        [[1.1071e-01],\n",
      "         [1.3677e-01],\n",
      "         [1.1772e-01],\n",
      "         [5.5922e-01]],\n",
      "\n",
      "        [[5.7791e-02],\n",
      "         [8.3686e-01],\n",
      "         [7.3640e-02],\n",
      "         [4.3217e-02]],\n",
      "\n",
      "        [[6.4802e-04],\n",
      "         [3.9341e-02],\n",
      "         [7.8116e-01],\n",
      "         [1.2041e-01]],\n",
      "\n",
      "        [[3.5779e-01],\n",
      "         [3.4934e-01],\n",
      "         [4.2067e-02],\n",
      "         [2.3818e-01]],\n",
      "\n",
      "        [[5.6770e-01],\n",
      "         [1.9207e-01],\n",
      "         [2.8855e-01],\n",
      "         [3.9860e-03]],\n",
      "\n",
      "        [[1.7069e-02],\n",
      "         [8.1437e-01],\n",
      "         [2.2111e-01],\n",
      "         [4.6659e-03]],\n",
      "\n",
      "        [[7.3925e-02],\n",
      "         [2.4488e-01],\n",
      "         [5.4082e-01],\n",
      "         [6.1677e-02]],\n",
      "\n",
      "        [[4.8233e-01],\n",
      "         [1.7745e-03],\n",
      "         [6.0088e-01],\n",
      "         [1.7506e-03]],\n",
      "\n",
      "        [[1.0309e-01],\n",
      "         [2.7670e-01],\n",
      "         [1.6821e-01],\n",
      "         [3.6973e-01]],\n",
      "\n",
      "        [[7.1621e-01],\n",
      "         [1.5464e-01],\n",
      "         [5.3342e-04],\n",
      "         [6.5448e-02]],\n",
      "\n",
      "        [[4.1062e-01],\n",
      "         [2.9289e-01],\n",
      "         [1.2698e-03],\n",
      "         [2.4936e-01]],\n",
      "\n",
      "        [[8.9438e-02],\n",
      "         [3.9994e-01],\n",
      "         [9.5908e-03],\n",
      "         [4.8382e-01]],\n",
      "\n",
      "        [[1.4376e-01],\n",
      "         [2.9670e-02],\n",
      "         [4.3286e-02],\n",
      "         [8.1416e-01]],\n",
      "\n",
      "        [[1.3859e-03],\n",
      "         [8.9913e-02],\n",
      "         [3.2296e-01],\n",
      "         [5.9658e-01]],\n",
      "\n",
      "        [[5.6289e-01],\n",
      "         [1.5668e-01],\n",
      "         [2.7179e-01],\n",
      "         [8.7484e-04]],\n",
      "\n",
      "        [[6.5434e-03],\n",
      "         [4.6146e-01],\n",
      "         [1.1840e-01],\n",
      "         [4.2549e-01]],\n",
      "\n",
      "        [[6.6562e-03],\n",
      "         [6.4174e-01],\n",
      "         [7.1398e-02],\n",
      "         [2.6018e-01]],\n",
      "\n",
      "        [[1.1031e-01],\n",
      "         [6.7800e-02],\n",
      "         [7.8241e-01],\n",
      "         [1.4860e-02]],\n",
      "\n",
      "        [[6.3389e-01],\n",
      "         [1.7100e-02],\n",
      "         [1.4966e-01],\n",
      "         [1.6853e-01]],\n",
      "\n",
      "        [[6.8847e-02],\n",
      "         [4.2094e-01],\n",
      "         [3.1241e-01],\n",
      "         [3.1255e-01]],\n",
      "\n",
      "        [[4.6155e-02],\n",
      "         [6.4288e-01],\n",
      "         [2.2774e-01],\n",
      "         [8.1033e-02]],\n",
      "\n",
      "        [[5.9875e-02],\n",
      "         [1.9158e-02],\n",
      "         [4.1049e-01],\n",
      "         [5.4398e-01]],\n",
      "\n",
      "        [[4.3098e-01],\n",
      "         [4.5367e-04],\n",
      "         [3.6937e-01],\n",
      "         [1.8727e-01]],\n",
      "\n",
      "        [[1.8897e-02],\n",
      "         [6.9355e-01],\n",
      "         [5.5015e-02],\n",
      "         [3.6940e-01]],\n",
      "\n",
      "        [[6.8668e-02],\n",
      "         [9.2673e-02],\n",
      "         [1.6198e-02],\n",
      "         [7.9369e-01]],\n",
      "\n",
      "        [[5.2402e-01],\n",
      "         [6.1177e-01],\n",
      "         [9.5633e-03],\n",
      "         [5.2383e-03]],\n",
      "\n",
      "        [[1.6612e-01],\n",
      "         [3.9722e-01],\n",
      "         [9.1559e-02],\n",
      "         [3.5984e-01]],\n",
      "\n",
      "        [[2.4451e-01],\n",
      "         [9.7133e-02],\n",
      "         [4.0445e-02],\n",
      "         [6.0106e-01]],\n",
      "\n",
      "        [[4.9313e-02],\n",
      "         [8.3433e-02],\n",
      "         [4.6179e-01],\n",
      "         [3.8371e-01]],\n",
      "\n",
      "        [[3.3052e-01],\n",
      "         [1.4381e-01],\n",
      "         [2.6762e-02],\n",
      "         [4.8235e-01]],\n",
      "\n",
      "        [[3.0001e-01],\n",
      "         [3.0032e-03],\n",
      "         [3.8752e-01],\n",
      "         [2.9262e-01]],\n",
      "\n",
      "        [[1.7691e-01],\n",
      "         [2.1049e-01],\n",
      "         [5.1886e-01],\n",
      "         [2.1594e-01]],\n",
      "\n",
      "        [[3.7293e-01],\n",
      "         [6.7210e-02],\n",
      "         [6.3035e-01],\n",
      "         [1.0388e-03]],\n",
      "\n",
      "        [[6.7963e-05],\n",
      "         [2.9993e-01],\n",
      "         [3.2098e-01],\n",
      "         [3.0613e-01]],\n",
      "\n",
      "        [[7.9866e-01],\n",
      "         [2.5469e-01],\n",
      "         [9.5242e-03],\n",
      "         [1.1272e-02]],\n",
      "\n",
      "        [[1.7993e-01],\n",
      "         [7.1180e-05],\n",
      "         [1.0459e-01],\n",
      "         [7.1346e-01]],\n",
      "\n",
      "        [[8.6207e-03],\n",
      "         [4.2033e-01],\n",
      "         [5.7288e-04],\n",
      "         [6.0987e-01]],\n",
      "\n",
      "        [[1.1229e-01],\n",
      "         [4.7806e-03],\n",
      "         [8.9582e-01],\n",
      "         [1.0183e-02]],\n",
      "\n",
      "        [[7.9583e-02],\n",
      "         [7.0602e-01],\n",
      "         [2.0057e-01],\n",
      "         [7.8066e-03]],\n",
      "\n",
      "        [[4.7347e-02],\n",
      "         [7.2261e-02],\n",
      "         [8.9339e-01],\n",
      "         [1.7475e-02]],\n",
      "\n",
      "        [[4.0283e-03],\n",
      "         [4.6820e-01],\n",
      "         [1.8855e-01],\n",
      "         [3.8803e-01]],\n",
      "\n",
      "        [[9.5315e-03],\n",
      "         [1.5836e-02],\n",
      "         [3.6008e-01],\n",
      "         [7.0977e-01]],\n",
      "\n",
      "        [[1.5669e-01],\n",
      "         [1.5943e-01],\n",
      "         [5.0824e-02],\n",
      "         [5.8479e-01]],\n",
      "\n",
      "        [[8.1711e-02],\n",
      "         [2.8767e-01],\n",
      "         [1.4224e-02],\n",
      "         [5.4770e-01]],\n",
      "\n",
      "        [[5.7360e-01],\n",
      "         [4.5553e-01],\n",
      "         [4.4480e-05],\n",
      "         [6.5858e-03]],\n",
      "\n",
      "        [[5.2527e-01],\n",
      "         [4.3911e-01],\n",
      "         [1.1834e-01],\n",
      "         [1.3664e-03]],\n",
      "\n",
      "        [[1.5871e-01],\n",
      "         [2.7638e-02],\n",
      "         [2.4564e-01],\n",
      "         [5.9783e-01]],\n",
      "\n",
      "        [[2.1106e-02],\n",
      "         [3.4413e-04],\n",
      "         [4.4923e-01],\n",
      "         [5.8304e-01]],\n",
      "\n",
      "        [[6.0560e-01],\n",
      "         [9.9035e-03],\n",
      "         [3.0263e-02],\n",
      "         [4.7623e-01]],\n",
      "\n",
      "        [[7.0742e-01],\n",
      "         [3.2757e-01],\n",
      "         [6.5857e-02],\n",
      "         [6.1443e-03]],\n",
      "\n",
      "        [[5.9944e-02],\n",
      "         [2.6959e-01],\n",
      "         [4.2522e-01],\n",
      "         [9.5640e-02]],\n",
      "\n",
      "        [[1.6171e-02],\n",
      "         [8.4860e-02],\n",
      "         [8.5685e-01],\n",
      "         [2.1902e-03]],\n",
      "\n",
      "        [[1.8525e-01],\n",
      "         [5.2584e-01],\n",
      "         [1.6314e-03],\n",
      "         [2.5769e-01]],\n",
      "\n",
      "        [[4.7149e-01],\n",
      "         [1.1765e-01],\n",
      "         [4.7224e-01],\n",
      "         [7.2431e-04]],\n",
      "\n",
      "        [[5.5797e-01],\n",
      "         [4.8298e-02],\n",
      "         [3.4872e-01],\n",
      "         [6.4576e-02]],\n",
      "\n",
      "        [[7.4031e-02],\n",
      "         [3.5111e-04],\n",
      "         [5.2934e-01],\n",
      "         [4.4775e-01]],\n",
      "\n",
      "        [[2.1741e-01],\n",
      "         [1.4344e-01],\n",
      "         [8.3986e-03],\n",
      "         [6.0843e-01]],\n",
      "\n",
      "        [[1.5692e-01],\n",
      "         [3.0667e-01],\n",
      "         [2.1967e-02],\n",
      "         [4.2874e-01]],\n",
      "\n",
      "        [[2.6684e-01],\n",
      "         [6.1229e-02],\n",
      "         [4.2133e-01],\n",
      "         [2.7163e-01]],\n",
      "\n",
      "        [[1.7071e-03],\n",
      "         [3.6391e-01],\n",
      "         [3.9072e-01],\n",
      "         [2.6977e-01]],\n",
      "\n",
      "        [[5.7307e-02],\n",
      "         [1.9020e-02],\n",
      "         [4.8294e-01],\n",
      "         [3.5627e-01]],\n",
      "\n",
      "        [[9.1304e-03],\n",
      "         [3.8486e-01],\n",
      "         [4.4362e-01],\n",
      "         [1.7190e-01]],\n",
      "\n",
      "        [[1.1234e-01],\n",
      "         [7.1680e-01],\n",
      "         [4.0029e-02],\n",
      "         [1.7092e-01]],\n",
      "\n",
      "        [[1.8509e-04],\n",
      "         [5.4680e-01],\n",
      "         [1.7125e-01],\n",
      "         [2.9576e-01]],\n",
      "\n",
      "        [[2.5695e-02],\n",
      "         [2.1931e-01],\n",
      "         [9.2750e-02],\n",
      "         [5.7273e-01]],\n",
      "\n",
      "        [[4.3115e-01],\n",
      "         [6.5569e-02],\n",
      "         [6.0061e-01],\n",
      "         [2.1411e-02]],\n",
      "\n",
      "        [[3.8279e-02],\n",
      "         [2.6895e-01],\n",
      "         [9.9221e-03],\n",
      "         [6.9752e-01]],\n",
      "\n",
      "        [[7.1734e-02],\n",
      "         [3.7816e-01],\n",
      "         [1.6574e-01],\n",
      "         [3.9967e-01]],\n",
      "\n",
      "        [[9.1798e-06],\n",
      "         [4.1133e-01],\n",
      "         [1.0732e-01],\n",
      "         [5.6815e-01]],\n",
      "\n",
      "        [[7.9803e-01],\n",
      "         [1.2670e-03],\n",
      "         [3.1284e-02],\n",
      "         [1.3443e-01]],\n",
      "\n",
      "        [[2.1867e-02],\n",
      "         [3.3578e-01],\n",
      "         [1.8591e-01],\n",
      "         [3.1425e-01]],\n",
      "\n",
      "        [[5.1348e-02],\n",
      "         [2.9541e-01],\n",
      "         [2.8175e-01],\n",
      "         [4.3540e-01]],\n",
      "\n",
      "        [[3.0272e-01],\n",
      "         [1.2559e-01],\n",
      "         [4.9799e-01],\n",
      "         [4.6354e-03]],\n",
      "\n",
      "        [[7.6709e-01],\n",
      "         [3.0265e-02],\n",
      "         [1.4531e-01],\n",
      "         [6.2061e-02]],\n",
      "\n",
      "        [[5.2560e-02],\n",
      "         [8.4865e-01],\n",
      "         [7.4018e-03],\n",
      "         [2.4357e-02]],\n",
      "\n",
      "        [[5.5659e-01],\n",
      "         [5.4359e-02],\n",
      "         [7.5982e-02],\n",
      "         [1.3770e-01]],\n",
      "\n",
      "        [[2.9785e-01],\n",
      "         [3.1198e-02],\n",
      "         [6.8444e-02],\n",
      "         [2.9506e-01]],\n",
      "\n",
      "        [[3.4457e-03],\n",
      "         [9.9622e-02],\n",
      "         [3.5067e-01],\n",
      "         [4.8315e-01]],\n",
      "\n",
      "        [[1.1275e-02],\n",
      "         [7.3101e-01],\n",
      "         [3.3892e-01],\n",
      "         [4.9204e-03]],\n",
      "\n",
      "        [[2.6114e-01],\n",
      "         [3.4486e-01],\n",
      "         [3.0884e-01],\n",
      "         [2.6794e-02]],\n",
      "\n",
      "        [[9.7439e-03],\n",
      "         [1.1732e-02],\n",
      "         [9.0368e-01],\n",
      "         [5.1706e-02]],\n",
      "\n",
      "        [[2.6979e-01],\n",
      "         [3.0852e-04],\n",
      "         [7.4754e-01],\n",
      "         [6.5423e-03]],\n",
      "\n",
      "        [[1.8738e-01],\n",
      "         [8.3841e-03],\n",
      "         [5.3112e-01],\n",
      "         [3.3086e-01]],\n",
      "\n",
      "        [[3.6400e-02],\n",
      "         [5.8601e-01],\n",
      "         [3.6277e-03],\n",
      "         [4.2108e-01]],\n",
      "\n",
      "        [[5.3123e-01],\n",
      "         [3.3172e-01],\n",
      "         [6.1647e-03],\n",
      "         [2.7217e-01]],\n",
      "\n",
      "        [[5.4967e-01],\n",
      "         [1.1595e-01],\n",
      "         [1.9309e-01],\n",
      "         [8.8551e-02]],\n",
      "\n",
      "        [[1.0787e-02],\n",
      "         [8.1579e-01],\n",
      "         [2.1211e-01],\n",
      "         [2.1399e-02]],\n",
      "\n",
      "        [[3.0383e-01],\n",
      "         [4.1199e-02],\n",
      "         [4.7384e-02],\n",
      "         [5.9554e-01]],\n",
      "\n",
      "        [[6.0939e-01],\n",
      "         [1.0188e-02],\n",
      "         [3.9927e-01],\n",
      "         [1.4597e-01]],\n",
      "\n",
      "        [[3.5970e-02],\n",
      "         [2.2417e-01],\n",
      "         [4.3625e-01],\n",
      "         [3.0183e-01]],\n",
      "\n",
      "        [[6.1933e-01],\n",
      "         [2.2605e-01],\n",
      "         [5.1591e-02],\n",
      "         [2.6876e-02]],\n",
      "\n",
      "        [[3.9541e-02],\n",
      "         [5.3341e-01],\n",
      "         [1.2050e-01],\n",
      "         [4.0613e-01]],\n",
      "\n",
      "        [[3.4353e-03],\n",
      "         [6.9322e-01],\n",
      "         [1.6739e-01],\n",
      "         [1.0008e-01]],\n",
      "\n",
      "        [[1.9071e-01],\n",
      "         [2.1554e-02],\n",
      "         [6.1255e-01],\n",
      "         [8.3316e-02]],\n",
      "\n",
      "        [[6.6897e-01],\n",
      "         [3.2431e-01],\n",
      "         [1.1618e-01],\n",
      "         [7.7551e-04]],\n",
      "\n",
      "        [[5.9210e-02],\n",
      "         [1.0241e-01],\n",
      "         [7.2600e-01],\n",
      "         [3.5231e-02]],\n",
      "\n",
      "        [[3.3397e-01],\n",
      "         [5.0355e-01],\n",
      "         [5.0265e-02],\n",
      "         [1.5281e-01]],\n",
      "\n",
      "        [[1.6987e-02],\n",
      "         [3.4287e-01],\n",
      "         [4.6212e-01],\n",
      "         [1.3296e-01]],\n",
      "\n",
      "        [[8.4025e-04],\n",
      "         [4.5999e-01],\n",
      "         [9.6819e-02],\n",
      "         [5.2004e-01]],\n",
      "\n",
      "        [[1.9684e-03],\n",
      "         [5.2738e-01],\n",
      "         [1.3322e-01],\n",
      "         [2.1784e-01]],\n",
      "\n",
      "        [[3.2653e-01],\n",
      "         [7.0236e-01],\n",
      "         [1.1086e-02],\n",
      "         [2.1116e-03]],\n",
      "\n",
      "        [[8.7072e-02],\n",
      "         [8.5774e-02],\n",
      "         [1.9414e-02],\n",
      "         [6.8664e-01]],\n",
      "\n",
      "        [[3.7433e-01],\n",
      "         [6.4387e-02],\n",
      "         [2.4261e-01],\n",
      "         [4.5330e-01]],\n",
      "\n",
      "        [[7.5481e-02],\n",
      "         [9.3982e-05],\n",
      "         [2.8405e-01],\n",
      "         [7.4178e-01]],\n",
      "\n",
      "        [[1.0353e-01],\n",
      "         [3.7589e-01],\n",
      "         [3.3133e-01],\n",
      "         [2.2254e-01]],\n",
      "\n",
      "        [[8.8721e-02],\n",
      "         [4.1781e-01],\n",
      "         [3.7945e-02],\n",
      "         [8.9752e-02]],\n",
      "\n",
      "        [[2.9698e-03],\n",
      "         [1.5266e-04],\n",
      "         [5.7784e-01],\n",
      "         [6.0976e-01]],\n",
      "\n",
      "        [[5.2122e-03],\n",
      "         [2.5407e-01],\n",
      "         [6.3103e-01],\n",
      "         [7.4225e-02]],\n",
      "\n",
      "        [[4.0357e-03],\n",
      "         [1.8767e-01],\n",
      "         [5.6776e-03],\n",
      "         [8.5720e-01]],\n",
      "\n",
      "        [[5.9535e-01],\n",
      "         [5.6378e-02],\n",
      "         [5.5774e-01],\n",
      "         [1.2569e-02]],\n",
      "\n",
      "        [[4.8931e-02],\n",
      "         [1.2823e-01],\n",
      "         [5.9078e-01],\n",
      "         [9.9252e-02]],\n",
      "\n",
      "        [[1.4528e-01],\n",
      "         [3.0375e-01],\n",
      "         [5.5597e-02],\n",
      "         [5.3041e-01]],\n",
      "\n",
      "        [[2.9478e-01],\n",
      "         [2.7856e-02],\n",
      "         [3.4397e-01],\n",
      "         [2.8938e-01]],\n",
      "\n",
      "        [[7.6187e-01],\n",
      "         [9.2589e-03],\n",
      "         [2.4713e-01],\n",
      "         [2.6244e-02]],\n",
      "\n",
      "        [[1.3766e-02],\n",
      "         [5.7411e-01],\n",
      "         [4.6066e-01],\n",
      "         [3.7034e-02]],\n",
      "\n",
      "        [[4.9340e-01],\n",
      "         [2.6650e-01],\n",
      "         [9.7282e-02],\n",
      "         [1.3151e-02]],\n",
      "\n",
      "        [[3.3179e-03],\n",
      "         [5.3184e-01],\n",
      "         [5.0141e-01],\n",
      "         [6.0530e-02]],\n",
      "\n",
      "        [[2.5456e-01],\n",
      "         [1.2137e-01],\n",
      "         [1.2607e-01],\n",
      "         [4.4153e-01]],\n",
      "\n",
      "        [[5.9580e-01],\n",
      "         [5.7578e-02],\n",
      "         [1.4080e-01],\n",
      "         [4.9855e-03]],\n",
      "\n",
      "        [[1.0636e-02],\n",
      "         [3.2052e-01],\n",
      "         [6.6283e-03],\n",
      "         [6.0567e-01]],\n",
      "\n",
      "        [[4.2324e-03],\n",
      "         [7.3776e-01],\n",
      "         [7.4329e-02],\n",
      "         [1.3618e-01]],\n",
      "\n",
      "        [[5.2423e-01],\n",
      "         [3.3981e-03],\n",
      "         [1.3237e-01],\n",
      "         [3.7629e-01]],\n",
      "\n",
      "        [[3.8784e-01],\n",
      "         [7.9853e-02],\n",
      "         [1.0012e-02],\n",
      "         [4.9077e-01]],\n",
      "\n",
      "        [[1.1505e-02],\n",
      "         [8.7687e-01],\n",
      "         [5.5205e-02],\n",
      "         [3.8645e-03]],\n",
      "\n",
      "        [[4.9669e-03],\n",
      "         [3.1950e-01],\n",
      "         [1.6152e-01],\n",
      "         [5.1718e-01]],\n",
      "\n",
      "        [[1.1330e-01],\n",
      "         [7.5749e-01],\n",
      "         [7.9047e-02],\n",
      "         [3.3354e-02]],\n",
      "\n",
      "        [[3.0010e-01],\n",
      "         [1.8798e-03],\n",
      "         [1.2269e-02],\n",
      "         [6.8772e-01]],\n",
      "\n",
      "        [[4.2192e-01],\n",
      "         [4.8514e-04],\n",
      "         [2.3240e-01],\n",
      "         [4.0049e-01]],\n",
      "\n",
      "        [[2.7671e-02],\n",
      "         [4.1276e-01],\n",
      "         [5.6747e-02],\n",
      "         [5.8093e-01]],\n",
      "\n",
      "        [[5.4836e-03],\n",
      "         [1.5773e-01],\n",
      "         [2.4555e-01],\n",
      "         [2.7655e-01]],\n",
      "\n",
      "        [[3.0069e-01],\n",
      "         [7.5355e-01],\n",
      "         [7.8553e-04],\n",
      "         [5.6351e-03]],\n",
      "\n",
      "        [[9.4932e-03],\n",
      "         [1.9397e-01],\n",
      "         [5.4968e-01],\n",
      "         [3.4082e-01]],\n",
      "\n",
      "        [[1.1477e-02],\n",
      "         [1.0992e-02],\n",
      "         [5.5791e-01],\n",
      "         [4.4998e-01]],\n",
      "\n",
      "        [[4.4340e-01],\n",
      "         [1.8917e-04],\n",
      "         [5.2000e-01],\n",
      "         [5.3318e-02]],\n",
      "\n",
      "        [[4.2660e-01],\n",
      "         [1.3215e-01],\n",
      "         [1.6156e-01],\n",
      "         [2.4748e-01]],\n",
      "\n",
      "        [[5.9467e-01],\n",
      "         [4.7288e-02],\n",
      "         [2.5541e-01],\n",
      "         [4.9300e-02]],\n",
      "\n",
      "        [[5.7672e-01],\n",
      "         [1.9058e-01],\n",
      "         [2.9361e-01],\n",
      "         [4.8412e-02]],\n",
      "\n",
      "        [[9.1542e-02],\n",
      "         [5.6148e-01],\n",
      "         [4.7987e-01],\n",
      "         [1.7178e-03]],\n",
      "\n",
      "        [[7.6834e-02],\n",
      "         [7.6326e-01],\n",
      "         [1.7529e-01],\n",
      "         [1.4593e-02]],\n",
      "\n",
      "        [[1.4514e-01],\n",
      "         [9.8144e-02],\n",
      "         [4.3193e-01],\n",
      "         [3.8155e-01]],\n",
      "\n",
      "        [[2.4257e-01],\n",
      "         [4.3710e-01],\n",
      "         [1.0171e-01],\n",
      "         [2.9133e-01]],\n",
      "\n",
      "        [[4.9493e-02],\n",
      "         [8.4385e-01],\n",
      "         [7.0441e-03],\n",
      "         [1.3587e-01]],\n",
      "\n",
      "        [[3.4674e-01],\n",
      "         [2.3547e-01],\n",
      "         [1.9880e-01],\n",
      "         [3.1710e-01]],\n",
      "\n",
      "        [[8.7069e-01],\n",
      "         [1.6521e-01],\n",
      "         [2.1008e-02],\n",
      "         [2.3640e-04]],\n",
      "\n",
      "        [[2.4726e-02],\n",
      "         [6.3859e-01],\n",
      "         [2.3449e-01],\n",
      "         [1.4085e-01]],\n",
      "\n",
      "        [[4.3026e-01],\n",
      "         [1.6185e-01],\n",
      "         [2.6981e-01],\n",
      "         [8.4870e-02]],\n",
      "\n",
      "        [[1.5702e-03],\n",
      "         [1.1008e-01],\n",
      "         [1.5210e-01],\n",
      "         [6.6737e-01]],\n",
      "\n",
      "        [[1.3690e-02],\n",
      "         [3.8206e-01],\n",
      "         [7.0105e-01],\n",
      "         [5.5969e-04]],\n",
      "\n",
      "        [[3.9476e-01],\n",
      "         [1.4930e-02],\n",
      "         [5.4898e-02],\n",
      "         [5.5188e-01]],\n",
      "\n",
      "        [[2.0080e-01],\n",
      "         [8.5601e-03],\n",
      "         [1.9274e-02],\n",
      "         [7.7178e-01]],\n",
      "\n",
      "        [[6.2590e-01],\n",
      "         [1.6028e-03],\n",
      "         [4.3436e-01],\n",
      "         [7.9835e-04]],\n",
      "\n",
      "        [[4.6369e-01],\n",
      "         [1.4469e-01],\n",
      "         [2.5439e-02],\n",
      "         [2.5481e-01]],\n",
      "\n",
      "        [[4.2820e-01],\n",
      "         [3.1663e-02],\n",
      "         [3.7470e-05],\n",
      "         [6.0694e-01]],\n",
      "\n",
      "        [[2.2087e-01],\n",
      "         [6.8207e-01],\n",
      "         [4.6892e-02],\n",
      "         [6.8733e-02]],\n",
      "\n",
      "        [[7.9301e-01],\n",
      "         [1.2608e-02],\n",
      "         [2.0267e-01],\n",
      "         [8.8017e-03]],\n",
      "\n",
      "        [[4.1843e-01],\n",
      "         [6.0740e-01],\n",
      "         [4.6673e-02],\n",
      "         [1.6045e-02]],\n",
      "\n",
      "        [[8.1205e-02],\n",
      "         [6.0518e-02],\n",
      "         [2.3077e-02],\n",
      "         [7.8138e-01]],\n",
      "\n",
      "        [[5.1154e-02],\n",
      "         [2.6799e-02],\n",
      "         [8.7726e-01],\n",
      "         [3.5595e-02]],\n",
      "\n",
      "        [[1.7778e-01],\n",
      "         [9.1022e-02],\n",
      "         [5.0593e-01],\n",
      "         [6.4643e-02]],\n",
      "\n",
      "        [[2.9312e-03],\n",
      "         [7.4911e-01],\n",
      "         [6.0230e-02],\n",
      "         [1.7881e-01]],\n",
      "\n",
      "        [[8.0712e-04],\n",
      "         [4.6978e-01],\n",
      "         [7.1815e-02],\n",
      "         [4.0849e-01]],\n",
      "\n",
      "        [[5.3925e-01],\n",
      "         [5.5307e-01],\n",
      "         [6.4984e-02],\n",
      "         [3.7357e-05]]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model_best=model_best.double()\n",
    "for batch_idx,data in enumerate(test_loader,0):\n",
    "        inputs_c,target_c=data\n",
    "        inputs_c =inputs_c.unsqueeze(1) #add one dimension(channel)\n",
    "        qq_pred=model_best(inputs_c)\n",
    "print(qq_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[2.8963e-01],\n",
      "         [4.0694e-03],\n",
      "         [3.1869e-01],\n",
      "         [3.8761e-01]],\n",
      "\n",
      "        [[6.3126e-01],\n",
      "         [5.6597e-02],\n",
      "         [6.3623e-02],\n",
      "         [2.4852e-01]],\n",
      "\n",
      "        [[3.0103e-01],\n",
      "         [2.7704e-01],\n",
      "         [3.8906e-01],\n",
      "         [3.2867e-02]],\n",
      "\n",
      "        [[2.4209e-01],\n",
      "         [1.4489e-01],\n",
      "         [4.0004e-01],\n",
      "         [2.1298e-01]],\n",
      "\n",
      "        [[7.7442e-03],\n",
      "         [8.2846e-02],\n",
      "         [6.3833e-01],\n",
      "         [2.7108e-01]],\n",
      "\n",
      "        [[3.6315e-02],\n",
      "         [6.1753e-01],\n",
      "         [2.5824e-01],\n",
      "         [8.7912e-02]],\n",
      "\n",
      "        [[2.9759e-01],\n",
      "         [4.1544e-02],\n",
      "         [5.4153e-01],\n",
      "         [1.1933e-01]],\n",
      "\n",
      "        [[2.8732e-01],\n",
      "         [6.2618e-01],\n",
      "         [8.2894e-02],\n",
      "         [3.5977e-03]],\n",
      "\n",
      "        [[5.9821e-01],\n",
      "         [9.2714e-02],\n",
      "         [1.7856e-01],\n",
      "         [1.3052e-01]],\n",
      "\n",
      "        [[3.6469e-02],\n",
      "         [4.1320e-01],\n",
      "         [4.8439e-01],\n",
      "         [6.5945e-02]],\n",
      "\n",
      "        [[3.5620e-01],\n",
      "         [2.9775e-01],\n",
      "         [1.3000e-01],\n",
      "         [2.1605e-01]],\n",
      "\n",
      "        [[7.8229e-03],\n",
      "         [1.2235e-02],\n",
      "         [9.6046e-01],\n",
      "         [1.9486e-02]],\n",
      "\n",
      "        [[1.3624e-01],\n",
      "         [1.9004e-01],\n",
      "         [2.6389e-02],\n",
      "         [6.4733e-01]],\n",
      "\n",
      "        [[3.2042e-03],\n",
      "         [5.8415e-02],\n",
      "         [1.1404e-02],\n",
      "         [9.2698e-01]],\n",
      "\n",
      "        [[3.4624e-02],\n",
      "         [4.5772e-02],\n",
      "         [1.9543e-01],\n",
      "         [7.2417e-01]],\n",
      "\n",
      "        [[9.1685e-01],\n",
      "         [2.1958e-02],\n",
      "         [5.1701e-02],\n",
      "         [9.4929e-03]],\n",
      "\n",
      "        [[1.5296e-02],\n",
      "         [6.0927e-01],\n",
      "         [3.5235e-01],\n",
      "         [2.3076e-02]],\n",
      "\n",
      "        [[6.6684e-01],\n",
      "         [2.2378e-03],\n",
      "         [2.0910e-01],\n",
      "         [1.2182e-01]],\n",
      "\n",
      "        [[1.0271e-01],\n",
      "         [3.4956e-01],\n",
      "         [4.6498e-01],\n",
      "         [8.2749e-02]],\n",
      "\n",
      "        [[3.9701e-01],\n",
      "         [2.1486e-01],\n",
      "         [3.8110e-01],\n",
      "         [7.0205e-03]],\n",
      "\n",
      "        [[4.6394e-03],\n",
      "         [5.3619e-01],\n",
      "         [1.4682e-01],\n",
      "         [3.1235e-01]],\n",
      "\n",
      "        [[4.0546e-01],\n",
      "         [3.0304e-01],\n",
      "         [1.6121e-01],\n",
      "         [1.3030e-01]],\n",
      "\n",
      "        [[5.9028e-01],\n",
      "         [1.9402e-01],\n",
      "         [3.0752e-03],\n",
      "         [2.1263e-01]],\n",
      "\n",
      "        [[3.8176e-01],\n",
      "         [2.6228e-03],\n",
      "         [1.2585e-02],\n",
      "         [6.0303e-01]],\n",
      "\n",
      "        [[1.8732e-01],\n",
      "         [2.1844e-02],\n",
      "         [7.2372e-01],\n",
      "         [6.7112e-02]],\n",
      "\n",
      "        [[7.6661e-01],\n",
      "         [1.4344e-01],\n",
      "         [1.7052e-02],\n",
      "         [7.2902e-02]],\n",
      "\n",
      "        [[2.0764e-01],\n",
      "         [3.4162e-01],\n",
      "         [2.8689e-01],\n",
      "         [1.6385e-01]],\n",
      "\n",
      "        [[4.8493e-02],\n",
      "         [1.7909e-01],\n",
      "         [7.2842e-01],\n",
      "         [4.3988e-02]],\n",
      "\n",
      "        [[8.9349e-02],\n",
      "         [6.4559e-01],\n",
      "         [1.9905e-01],\n",
      "         [6.6010e-02]],\n",
      "\n",
      "        [[2.8863e-01],\n",
      "         [3.9468e-02],\n",
      "         [4.3032e-01],\n",
      "         [2.4158e-01]],\n",
      "\n",
      "        [[9.5378e-02],\n",
      "         [1.0895e-01],\n",
      "         [2.2596e-01],\n",
      "         [5.6972e-01]],\n",
      "\n",
      "        [[1.0844e-01],\n",
      "         [2.2999e-01],\n",
      "         [2.2106e-01],\n",
      "         [4.4052e-01]],\n",
      "\n",
      "        [[4.1022e-02],\n",
      "         [4.6456e-01],\n",
      "         [2.2351e-01],\n",
      "         [2.7091e-01]],\n",
      "\n",
      "        [[2.5906e-01],\n",
      "         [3.7877e-01],\n",
      "         [7.6451e-02],\n",
      "         [2.8572e-01]],\n",
      "\n",
      "        [[1.8278e-02],\n",
      "         [8.5501e-01],\n",
      "         [9.2971e-02],\n",
      "         [3.3743e-02]],\n",
      "\n",
      "        [[2.6647e-02],\n",
      "         [1.4267e-01],\n",
      "         [7.1737e-01],\n",
      "         [1.1332e-01]],\n",
      "\n",
      "        [[4.6259e-01],\n",
      "         [1.9544e-01],\n",
      "         [1.0793e-01],\n",
      "         [2.3404e-01]],\n",
      "\n",
      "        [[1.1131e-02],\n",
      "         [1.2501e-02],\n",
      "         [1.5316e-01],\n",
      "         [8.2320e-01]],\n",
      "\n",
      "        [[7.3745e-02],\n",
      "         [1.3030e-01],\n",
      "         [1.9457e-01],\n",
      "         [6.0138e-01]],\n",
      "\n",
      "        [[5.6546e-02],\n",
      "         [7.8740e-01],\n",
      "         [5.9117e-02],\n",
      "         [9.6936e-02]],\n",
      "\n",
      "        [[9.7166e-03],\n",
      "         [4.4822e-02],\n",
      "         [7.1823e-01],\n",
      "         [2.2723e-01]],\n",
      "\n",
      "        [[5.8227e-01],\n",
      "         [2.4169e-01],\n",
      "         [6.3443e-02],\n",
      "         [1.1259e-01]],\n",
      "\n",
      "        [[6.4735e-01],\n",
      "         [1.2304e-01],\n",
      "         [2.1863e-01],\n",
      "         [1.0986e-02]],\n",
      "\n",
      "        [[3.5442e-02],\n",
      "         [7.6317e-01],\n",
      "         [1.8480e-01],\n",
      "         [1.6586e-02]],\n",
      "\n",
      "        [[8.0128e-02],\n",
      "         [2.4169e-01],\n",
      "         [6.1334e-01],\n",
      "         [6.4852e-02]],\n",
      "\n",
      "        [[3.3261e-01],\n",
      "         [7.1334e-03],\n",
      "         [6.5335e-01],\n",
      "         [6.9100e-03]],\n",
      "\n",
      "        [[2.2150e-01],\n",
      "         [3.6131e-01],\n",
      "         [1.7533e-01],\n",
      "         [2.4186e-01]],\n",
      "\n",
      "        [[8.2726e-01],\n",
      "         [1.2375e-01],\n",
      "         [5.2901e-03],\n",
      "         [4.3708e-02]],\n",
      "\n",
      "        [[4.9590e-01],\n",
      "         [3.2643e-01],\n",
      "         [7.8643e-03],\n",
      "         [1.6981e-01]],\n",
      "\n",
      "        [[7.2222e-02],\n",
      "         [3.5245e-01],\n",
      "         [2.5520e-02],\n",
      "         [5.4981e-01]],\n",
      "\n",
      "        [[8.6156e-02],\n",
      "         [3.7423e-02],\n",
      "         [4.9992e-02],\n",
      "         [8.2643e-01]],\n",
      "\n",
      "        [[4.9509e-03],\n",
      "         [8.2612e-02],\n",
      "         [2.8801e-01],\n",
      "         [6.2442e-01]],\n",
      "\n",
      "        [[7.7120e-01],\n",
      "         [1.0223e-01],\n",
      "         [1.2369e-01],\n",
      "         [2.8788e-03]],\n",
      "\n",
      "        [[1.4913e-02],\n",
      "         [1.8812e-01],\n",
      "         [1.2041e-01],\n",
      "         [6.7656e-01]],\n",
      "\n",
      "        [[1.5764e-02],\n",
      "         [6.8711e-01],\n",
      "         [1.0619e-01],\n",
      "         [1.9094e-01]],\n",
      "\n",
      "        [[1.2755e-01],\n",
      "         [4.9911e-02],\n",
      "         [8.0261e-01],\n",
      "         [1.9936e-02]],\n",
      "\n",
      "        [[8.0431e-01],\n",
      "         [3.2926e-02],\n",
      "         [8.9892e-02],\n",
      "         [7.2873e-02]],\n",
      "\n",
      "        [[5.9541e-02],\n",
      "         [3.8409e-01],\n",
      "         [3.6794e-01],\n",
      "         [1.8843e-01]],\n",
      "\n",
      "        [[8.3274e-02],\n",
      "         [6.8608e-01],\n",
      "         [1.2834e-01],\n",
      "         [1.0231e-01]],\n",
      "\n",
      "        [[9.4763e-02],\n",
      "         [1.0201e-02],\n",
      "         [2.7447e-01],\n",
      "         [6.2057e-01]],\n",
      "\n",
      "        [[5.1519e-01],\n",
      "         [4.1623e-03],\n",
      "         [3.4707e-01],\n",
      "         [1.3358e-01]],\n",
      "\n",
      "        [[2.4361e-02],\n",
      "         [6.3652e-01],\n",
      "         [8.2250e-02],\n",
      "         [2.5687e-01]],\n",
      "\n",
      "        [[2.1989e-02],\n",
      "         [8.2810e-02],\n",
      "         [9.6125e-03],\n",
      "         [8.8559e-01]],\n",
      "\n",
      "        [[3.1493e-01],\n",
      "         [6.4720e-01],\n",
      "         [2.4102e-02],\n",
      "         [1.3777e-02]],\n",
      "\n",
      "        [[2.7876e-01],\n",
      "         [2.6096e-01],\n",
      "         [7.6034e-02],\n",
      "         [3.8424e-01]],\n",
      "\n",
      "        [[1.0990e-01],\n",
      "         [1.2987e-01],\n",
      "         [6.2755e-02],\n",
      "         [6.9748e-01]],\n",
      "\n",
      "        [[5.3091e-02],\n",
      "         [1.2421e-01],\n",
      "         [3.7205e-01],\n",
      "         [4.5065e-01]],\n",
      "\n",
      "        [[2.8351e-01],\n",
      "         [9.9047e-02],\n",
      "         [4.2511e-02],\n",
      "         [5.7493e-01]],\n",
      "\n",
      "        [[2.1226e-01],\n",
      "         [8.3873e-03],\n",
      "         [4.3389e-01],\n",
      "         [3.4547e-01]],\n",
      "\n",
      "        [[3.6403e-02],\n",
      "         [4.6430e-01],\n",
      "         [2.1682e-01],\n",
      "         [2.8247e-01]],\n",
      "\n",
      "        [[4.9833e-01],\n",
      "         [1.0985e-01],\n",
      "         [3.8916e-01],\n",
      "         [2.6584e-03]],\n",
      "\n",
      "        [[2.4021e-03],\n",
      "         [4.1933e-01],\n",
      "         [2.5662e-01],\n",
      "         [3.2165e-01]],\n",
      "\n",
      "        [[7.6026e-01],\n",
      "         [2.0270e-01],\n",
      "         [1.7115e-02],\n",
      "         [1.9921e-02]],\n",
      "\n",
      "        [[2.2800e-01],\n",
      "         [3.9535e-03],\n",
      "         [1.1063e-01],\n",
      "         [6.5742e-01]],\n",
      "\n",
      "        [[6.2450e-03],\n",
      "         [5.2238e-01],\n",
      "         [2.6164e-03],\n",
      "         [4.6876e-01]],\n",
      "\n",
      "        [[7.5096e-02],\n",
      "         [5.8218e-03],\n",
      "         [9.1116e-01],\n",
      "         [7.9186e-03]],\n",
      "\n",
      "        [[6.7641e-02],\n",
      "         [7.8061e-01],\n",
      "         [1.4043e-01],\n",
      "         [1.1320e-02]],\n",
      "\n",
      "        [[7.7067e-02],\n",
      "         [7.3116e-02],\n",
      "         [8.3201e-01],\n",
      "         [1.7811e-02]],\n",
      "\n",
      "        [[7.1429e-03],\n",
      "         [5.9976e-01],\n",
      "         [1.3874e-01],\n",
      "         [2.5436e-01]],\n",
      "\n",
      "        [[1.6651e-02],\n",
      "         [1.9583e-02],\n",
      "         [2.4610e-01],\n",
      "         [7.1767e-01]],\n",
      "\n",
      "        [[1.0608e-01],\n",
      "         [2.3154e-01],\n",
      "         [5.5012e-02],\n",
      "         [6.0737e-01]],\n",
      "\n",
      "        [[1.1277e-01],\n",
      "         [2.7849e-01],\n",
      "         [4.0718e-02],\n",
      "         [5.6802e-01]],\n",
      "\n",
      "        [[6.3495e-01],\n",
      "         [3.4398e-01],\n",
      "         [3.8205e-03],\n",
      "         [1.7251e-02]],\n",
      "\n",
      "        [[5.4192e-01],\n",
      "         [3.2794e-01],\n",
      "         [1.1918e-01],\n",
      "         [1.0961e-02]],\n",
      "\n",
      "        [[1.4200e-01],\n",
      "         [4.2295e-02],\n",
      "         [1.7540e-01],\n",
      "         [6.4030e-01]],\n",
      "\n",
      "        [[3.0215e-02],\n",
      "         [9.1355e-03],\n",
      "         [4.4079e-01],\n",
      "         [5.1986e-01]],\n",
      "\n",
      "        [[5.8617e-01],\n",
      "         [1.4543e-02],\n",
      "         [4.9284e-02],\n",
      "         [3.5001e-01]],\n",
      "\n",
      "        [[6.2223e-01],\n",
      "         [3.1709e-01],\n",
      "         [5.5099e-02],\n",
      "         [5.5857e-03]],\n",
      "\n",
      "        [[5.6016e-02],\n",
      "         [1.5585e-01],\n",
      "         [5.7293e-01],\n",
      "         [2.1521e-01]],\n",
      "\n",
      "        [[8.8878e-03],\n",
      "         [3.8800e-02],\n",
      "         [9.4789e-01],\n",
      "         [4.4177e-03]],\n",
      "\n",
      "        [[1.1142e-01],\n",
      "         [7.4141e-01],\n",
      "         [1.9462e-02],\n",
      "         [1.2771e-01]],\n",
      "\n",
      "        [[3.3910e-01],\n",
      "         [1.9881e-01],\n",
      "         [4.5180e-01],\n",
      "         [1.0289e-02]],\n",
      "\n",
      "        [[5.8241e-01],\n",
      "         [2.9280e-02],\n",
      "         [2.6543e-01],\n",
      "         [1.2288e-01]],\n",
      "\n",
      "        [[2.0439e-01],\n",
      "         [3.7002e-03],\n",
      "         [3.3940e-01],\n",
      "         [4.5251e-01]],\n",
      "\n",
      "        [[6.2862e-02],\n",
      "         [2.2514e-01],\n",
      "         [2.9866e-02],\n",
      "         [6.8213e-01]],\n",
      "\n",
      "        [[1.7513e-01],\n",
      "         [4.4304e-01],\n",
      "         [6.4546e-02],\n",
      "         [3.1728e-01]],\n",
      "\n",
      "        [[1.9323e-01],\n",
      "         [3.5301e-02],\n",
      "         [4.8984e-01],\n",
      "         [2.8162e-01]],\n",
      "\n",
      "        [[6.3557e-03],\n",
      "         [3.3215e-01],\n",
      "         [3.2059e-01],\n",
      "         [3.4091e-01]],\n",
      "\n",
      "        [[1.1411e-01],\n",
      "         [4.3194e-02],\n",
      "         [3.0776e-01],\n",
      "         [5.3493e-01]],\n",
      "\n",
      "        [[4.9995e-02],\n",
      "         [1.5622e-01],\n",
      "         [7.0992e-01],\n",
      "         [8.3867e-02]],\n",
      "\n",
      "        [[1.3247e-01],\n",
      "         [6.9950e-01],\n",
      "         [5.7941e-02],\n",
      "         [1.1009e-01]],\n",
      "\n",
      "        [[1.4467e-03],\n",
      "         [6.5013e-01],\n",
      "         [4.2250e-02],\n",
      "         [3.0617e-01]],\n",
      "\n",
      "        [[6.4310e-02],\n",
      "         [3.3680e-01],\n",
      "         [1.5814e-01],\n",
      "         [4.4075e-01]],\n",
      "\n",
      "        [[2.5651e-01],\n",
      "         [8.7425e-02],\n",
      "         [6.3007e-01],\n",
      "         [2.6002e-02]],\n",
      "\n",
      "        [[3.2555e-02],\n",
      "         [1.7927e-01],\n",
      "         [2.8957e-02],\n",
      "         [7.5922e-01]],\n",
      "\n",
      "        [[7.9616e-02],\n",
      "         [3.2477e-01],\n",
      "         [1.7884e-01],\n",
      "         [4.1677e-01]],\n",
      "\n",
      "        [[6.3655e-04],\n",
      "         [1.0828e-01],\n",
      "         [7.9542e-02],\n",
      "         [8.1154e-01]],\n",
      "\n",
      "        [[8.2604e-01],\n",
      "         [1.2632e-02],\n",
      "         [4.6780e-02],\n",
      "         [1.1455e-01]],\n",
      "\n",
      "        [[2.6847e-02],\n",
      "         [2.4158e-01],\n",
      "         [1.7481e-01],\n",
      "         [5.5677e-01]],\n",
      "\n",
      "        [[5.2721e-02],\n",
      "         [3.1697e-01],\n",
      "         [3.1324e-01],\n",
      "         [3.1707e-01]],\n",
      "\n",
      "        [[2.3191e-01],\n",
      "         [7.7226e-02],\n",
      "         [6.8385e-01],\n",
      "         [7.0170e-03]],\n",
      "\n",
      "        [[7.1895e-01],\n",
      "         [4.0890e-02],\n",
      "         [1.6597e-01],\n",
      "         [7.4189e-02]],\n",
      "\n",
      "        [[6.6968e-02],\n",
      "         [8.7070e-01],\n",
      "         [1.9920e-02],\n",
      "         [4.2409e-02]],\n",
      "\n",
      "        [[4.9550e-01],\n",
      "         [4.5410e-02],\n",
      "         [1.3377e-01],\n",
      "         [3.2532e-01]],\n",
      "\n",
      "        [[5.1508e-01],\n",
      "         [5.7665e-02],\n",
      "         [1.8195e-01],\n",
      "         [2.4531e-01]],\n",
      "\n",
      "        [[9.7417e-03],\n",
      "         [1.1907e-01],\n",
      "         [2.5093e-01],\n",
      "         [6.2026e-01]],\n",
      "\n",
      "        [[5.0923e-02],\n",
      "         [6.6454e-01],\n",
      "         [2.6668e-01],\n",
      "         [1.7863e-02]],\n",
      "\n",
      "        [[3.4354e-01],\n",
      "         [2.2182e-01],\n",
      "         [3.7646e-01],\n",
      "         [5.8181e-02]],\n",
      "\n",
      "        [[4.3599e-03],\n",
      "         [1.5444e-02],\n",
      "         [9.5803e-01],\n",
      "         [2.2166e-02]],\n",
      "\n",
      "        [[2.7941e-01],\n",
      "         [5.4768e-03],\n",
      "         [7.0869e-01],\n",
      "         [6.4264e-03]],\n",
      "\n",
      "        [[1.1760e-01],\n",
      "         [1.6519e-02],\n",
      "         [5.8505e-01],\n",
      "         [2.8083e-01]],\n",
      "\n",
      "        [[3.6824e-02],\n",
      "         [5.8768e-01],\n",
      "         [7.4063e-03],\n",
      "         [3.6809e-01]],\n",
      "\n",
      "        [[5.3671e-01],\n",
      "         [3.0602e-01],\n",
      "         [9.7300e-03],\n",
      "         [1.4754e-01]],\n",
      "\n",
      "        [[6.8914e-01],\n",
      "         [8.0274e-02],\n",
      "         [9.0063e-02],\n",
      "         [1.4053e-01]],\n",
      "\n",
      "        [[9.0817e-03],\n",
      "         [6.7296e-01],\n",
      "         [2.9385e-01],\n",
      "         [2.4108e-02]],\n",
      "\n",
      "        [[4.2768e-01],\n",
      "         [6.0166e-02],\n",
      "         [5.7759e-02],\n",
      "         [4.5440e-01]],\n",
      "\n",
      "        [[7.4764e-01],\n",
      "         [7.8424e-03],\n",
      "         [1.4179e-01],\n",
      "         [1.0274e-01]],\n",
      "\n",
      "        [[8.2185e-02],\n",
      "         [1.6405e-01],\n",
      "         [3.9383e-01],\n",
      "         [3.5993e-01]],\n",
      "\n",
      "        [[7.5589e-01],\n",
      "         [1.3333e-01],\n",
      "         [5.2979e-02],\n",
      "         [5.7800e-02]],\n",
      "\n",
      "        [[6.0260e-02],\n",
      "         [5.9769e-01],\n",
      "         [7.8203e-02],\n",
      "         [2.6385e-01]],\n",
      "\n",
      "        [[1.1395e-02],\n",
      "         [6.8242e-01],\n",
      "         [1.5148e-01],\n",
      "         [1.5470e-01]],\n",
      "\n",
      "        [[1.8388e-01],\n",
      "         [8.0343e-02],\n",
      "         [5.8220e-01],\n",
      "         [1.5358e-01]],\n",
      "\n",
      "        [[6.0171e-01],\n",
      "         [3.3663e-01],\n",
      "         [5.4808e-02],\n",
      "         [6.8521e-03]],\n",
      "\n",
      "        [[1.1031e-01],\n",
      "         [1.6850e-01],\n",
      "         [6.4810e-01],\n",
      "         [7.3093e-02]],\n",
      "\n",
      "        [[2.7915e-01],\n",
      "         [6.1109e-01],\n",
      "         [5.2175e-02],\n",
      "         [5.7583e-02]],\n",
      "\n",
      "        [[3.2950e-02],\n",
      "         [1.6079e-01],\n",
      "         [6.5304e-01],\n",
      "         [1.5322e-01]],\n",
      "\n",
      "        [[2.1950e-03],\n",
      "         [3.4322e-01],\n",
      "         [1.2393e-01],\n",
      "         [5.3065e-01]],\n",
      "\n",
      "        [[8.2212e-03],\n",
      "         [7.0044e-01],\n",
      "         [1.2440e-01],\n",
      "         [1.6694e-01]],\n",
      "\n",
      "        [[2.5264e-01],\n",
      "         [7.2032e-01],\n",
      "         [2.2050e-02],\n",
      "         [4.9946e-03]],\n",
      "\n",
      "        [[3.9394e-03],\n",
      "         [3.3956e-02],\n",
      "         [1.4485e-02],\n",
      "         [9.4762e-01]],\n",
      "\n",
      "        [[4.2116e-01],\n",
      "         [5.4742e-02],\n",
      "         [1.9942e-01],\n",
      "         [3.2468e-01]],\n",
      "\n",
      "        [[1.0233e-01],\n",
      "         [3.2681e-03],\n",
      "         [1.2181e-01],\n",
      "         [7.7259e-01]],\n",
      "\n",
      "        [[5.6994e-02],\n",
      "         [3.3482e-01],\n",
      "         [4.3641e-01],\n",
      "         [1.7177e-01]],\n",
      "\n",
      "        [[2.9496e-01],\n",
      "         [3.9882e-01],\n",
      "         [1.7718e-01],\n",
      "         [1.2903e-01]],\n",
      "\n",
      "        [[8.3151e-03],\n",
      "         [1.3186e-03],\n",
      "         [3.6713e-01],\n",
      "         [6.2324e-01]],\n",
      "\n",
      "        [[1.1484e-02],\n",
      "         [3.2532e-01],\n",
      "         [5.8393e-01],\n",
      "         [7.9273e-02]],\n",
      "\n",
      "        [[1.4811e-02],\n",
      "         [2.7306e-01],\n",
      "         [1.6201e-02],\n",
      "         [6.9593e-01]],\n",
      "\n",
      "        [[4.9179e-01],\n",
      "         [8.2737e-02],\n",
      "         [3.9055e-01],\n",
      "         [3.4927e-02]],\n",
      "\n",
      "        [[9.9645e-02],\n",
      "         [1.7168e-01],\n",
      "         [6.6375e-01],\n",
      "         [6.4930e-02]],\n",
      "\n",
      "        [[2.1012e-01],\n",
      "         [2.5108e-01],\n",
      "         [7.5239e-02],\n",
      "         [4.6356e-01]],\n",
      "\n",
      "        [[3.4329e-01],\n",
      "         [3.9608e-02],\n",
      "         [4.2133e-01],\n",
      "         [1.9578e-01]],\n",
      "\n",
      "        [[6.8571e-01],\n",
      "         [8.9659e-03],\n",
      "         [2.7374e-01],\n",
      "         [3.1583e-02]],\n",
      "\n",
      "        [[2.8681e-02],\n",
      "         [6.3363e-01],\n",
      "         [2.8597e-01],\n",
      "         [5.1718e-02]],\n",
      "\n",
      "        [[5.0010e-01],\n",
      "         [3.7267e-01],\n",
      "         [7.8538e-02],\n",
      "         [4.8691e-02]],\n",
      "\n",
      "        [[9.5130e-03],\n",
      "         [2.3047e-01],\n",
      "         [6.9935e-01],\n",
      "         [6.0670e-02]],\n",
      "\n",
      "        [[3.3253e-01],\n",
      "         [1.2949e-01],\n",
      "         [1.5172e-01],\n",
      "         [3.8626e-01]],\n",
      "\n",
      "        [[8.8686e-01],\n",
      "         [3.9718e-02],\n",
      "         [5.8294e-02],\n",
      "         [1.5131e-02]],\n",
      "\n",
      "        [[1.6269e-02],\n",
      "         [3.6903e-01],\n",
      "         [9.3208e-03],\n",
      "         [6.0538e-01]],\n",
      "\n",
      "        [[6.9108e-03],\n",
      "         [6.6051e-01],\n",
      "         [1.0669e-01],\n",
      "         [2.2588e-01]],\n",
      "\n",
      "        [[6.0555e-01],\n",
      "         [5.6960e-03],\n",
      "         [8.4394e-02],\n",
      "         [3.0436e-01]],\n",
      "\n",
      "        [[3.0726e-01],\n",
      "         [1.6893e-01],\n",
      "         [2.6843e-02],\n",
      "         [4.9697e-01]],\n",
      "\n",
      "        [[2.8468e-02],\n",
      "         [8.4103e-01],\n",
      "         [1.0801e-01],\n",
      "         [2.2498e-02]],\n",
      "\n",
      "        [[6.2723e-03],\n",
      "         [3.9042e-01],\n",
      "         [1.0823e-01],\n",
      "         [4.9508e-01]],\n",
      "\n",
      "        [[2.2934e-01],\n",
      "         [6.1894e-01],\n",
      "         [1.1341e-01],\n",
      "         [3.8309e-02]],\n",
      "\n",
      "        [[1.8734e-01],\n",
      "         [2.7488e-03],\n",
      "         [1.4713e-02],\n",
      "         [7.9520e-01]],\n",
      "\n",
      "        [[4.5778e-01],\n",
      "         [4.6376e-03],\n",
      "         [4.4413e-01],\n",
      "         [9.3454e-02]],\n",
      "\n",
      "        [[6.7581e-02],\n",
      "         [3.7196e-01],\n",
      "         [2.2873e-02],\n",
      "         [5.3759e-01]],\n",
      "\n",
      "        [[3.1029e-02],\n",
      "         [3.8238e-01],\n",
      "         [2.8679e-01],\n",
      "         [2.9979e-01]],\n",
      "\n",
      "        [[1.9800e-01],\n",
      "         [7.6891e-01],\n",
      "         [5.3192e-03],\n",
      "         [2.7773e-02]],\n",
      "\n",
      "        [[2.4164e-02],\n",
      "         [3.5133e-01],\n",
      "         [3.8309e-01],\n",
      "         [2.4141e-01]],\n",
      "\n",
      "        [[2.1995e-02],\n",
      "         [2.4625e-02],\n",
      "         [5.1251e-01],\n",
      "         [4.4087e-01]],\n",
      "\n",
      "        [[4.4323e-01],\n",
      "         [1.4841e-03],\n",
      "         [3.8784e-01],\n",
      "         [1.6745e-01]],\n",
      "\n",
      "        [[3.5568e-01],\n",
      "         [1.0741e-01],\n",
      "         [1.5723e-01],\n",
      "         [3.7968e-01]],\n",
      "\n",
      "        [[7.4286e-01],\n",
      "         [5.4155e-02],\n",
      "         [1.6466e-01],\n",
      "         [3.8327e-02]],\n",
      "\n",
      "        [[5.0946e-01],\n",
      "         [2.5363e-01],\n",
      "         [1.5808e-01],\n",
      "         [7.8836e-02]],\n",
      "\n",
      "        [[8.9562e-02],\n",
      "         [3.9039e-01],\n",
      "         [5.1512e-01],\n",
      "         [4.9255e-03]],\n",
      "\n",
      "        [[1.0938e-01],\n",
      "         [7.6544e-01],\n",
      "         [1.0736e-01],\n",
      "         [1.7820e-02]],\n",
      "\n",
      "        [[1.0697e-01],\n",
      "         [7.6675e-02],\n",
      "         [4.2251e-01],\n",
      "         [3.9385e-01]],\n",
      "\n",
      "        [[2.6722e-01],\n",
      "         [2.7670e-01],\n",
      "         [2.0651e-01],\n",
      "         [2.4956e-01]],\n",
      "\n",
      "        [[3.6843e-02],\n",
      "         [8.0853e-01],\n",
      "         [1.3016e-02],\n",
      "         [1.4161e-01]],\n",
      "\n",
      "        [[3.3267e-01],\n",
      "         [3.3194e-01],\n",
      "         [1.7836e-01],\n",
      "         [1.5702e-01]],\n",
      "\n",
      "        [[8.1848e-01],\n",
      "         [1.6180e-01],\n",
      "         [1.6669e-02],\n",
      "         [3.0461e-03]],\n",
      "\n",
      "        [[1.9644e-02],\n",
      "         [6.0033e-01],\n",
      "         [2.6332e-01],\n",
      "         [1.1671e-01]],\n",
      "\n",
      "        [[4.7841e-01],\n",
      "         [1.7431e-01],\n",
      "         [1.9619e-01],\n",
      "         [1.5109e-01]],\n",
      "\n",
      "        [[1.1723e-02],\n",
      "         [1.0541e-01],\n",
      "         [2.0508e-01],\n",
      "         [6.7779e-01]],\n",
      "\n",
      "        [[2.4008e-02],\n",
      "         [5.2936e-01],\n",
      "         [4.4320e-01],\n",
      "         [3.4286e-03]],\n",
      "\n",
      "        [[3.3176e-01],\n",
      "         [1.5427e-02],\n",
      "         [6.9687e-02],\n",
      "         [5.8313e-01]],\n",
      "\n",
      "        [[2.2542e-01],\n",
      "         [3.1315e-02],\n",
      "         [4.9604e-02],\n",
      "         [6.9366e-01]],\n",
      "\n",
      "        [[6.1631e-01],\n",
      "         [6.6295e-03],\n",
      "         [3.7120e-01],\n",
      "         [5.8589e-03]],\n",
      "\n",
      "        [[3.3388e-01],\n",
      "         [1.2966e-01],\n",
      "         [5.0357e-02],\n",
      "         [4.8610e-01]],\n",
      "\n",
      "        [[3.7639e-01],\n",
      "         [4.8212e-02],\n",
      "         [2.5389e-03],\n",
      "         [5.7285e-01]],\n",
      "\n",
      "        [[1.1676e-01],\n",
      "         [7.8632e-01],\n",
      "         [4.9437e-02],\n",
      "         [4.7480e-02]],\n",
      "\n",
      "        [[8.6716e-01],\n",
      "         [1.7338e-02],\n",
      "         [1.0019e-01],\n",
      "         [1.5312e-02]],\n",
      "\n",
      "        [[3.1350e-01],\n",
      "         [6.0206e-01],\n",
      "         [4.7597e-02],\n",
      "         [3.6842e-02]],\n",
      "\n",
      "        [[6.7171e-02],\n",
      "         [5.6979e-02],\n",
      "         [2.4444e-02],\n",
      "         [8.5141e-01]],\n",
      "\n",
      "        [[1.2963e-01],\n",
      "         [2.2949e-02],\n",
      "         [7.3968e-01],\n",
      "         [1.0774e-01]],\n",
      "\n",
      "        [[2.7689e-01],\n",
      "         [9.1623e-02],\n",
      "         [5.8569e-01],\n",
      "         [4.5799e-02]],\n",
      "\n",
      "        [[2.8495e-03],\n",
      "         [8.5358e-01],\n",
      "         [1.6136e-02],\n",
      "         [1.2744e-01]],\n",
      "\n",
      "        [[9.4881e-03],\n",
      "         [6.8101e-01],\n",
      "         [6.6044e-02],\n",
      "         [2.4345e-01]],\n",
      "\n",
      "        [[4.6451e-01],\n",
      "         [4.5012e-01],\n",
      "         [8.3852e-02],\n",
      "         [1.5176e-03]]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "print(target_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.002867948432681673\n"
     ]
    }
   ],
   "source": [
    "print(abs(LA.norm(np.matrix(qq_pred.tolist()[0])-np.matrix(target_c.tolist()[0])))**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ -0.51294741   0.6178873   51.62306908   5.44823032   3.65426827\n",
      "    -3.01093356 -13.53950356  -1.56025288  -1.44079351   1.56296469\n",
      "    24.87462745   2.95383685   2.61124672   1.3674396   34.13301594\n",
      "   -11.55648713  -8.26357611   4.91939291 -53.27643637 -24.86528104\n",
      "     4.00894988  -2.32117973  -2.06253676  -2.30004909]\n",
      "  [  5.99095974  -4.49159199 -49.07075936 -21.89490308  -0.84235078\n",
      "   -10.51984445 -17.81029306   5.54598769  -2.81276269  -2.72091415\n",
      "    12.90401006   5.66574786  -2.6212928   -4.0328133  -31.22959827\n",
      "    -6.26539648  -4.24248741  -2.43607834  -1.89063748  28.46253585\n",
      "     2.43908376   2.6166561  -18.62812907  14.26094591]]]\n"
     ]
    }
   ],
   "source": [
    "print(np.array(inputs_c.tolist()[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>h_input</th>\n",
       "      <th>q_predict</th>\n",
       "      <th>q_real</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[[-0.512947407036421, 0.6178872998767779, 51....</td>\n",
       "      <td>[[0.5244445961101116], [0.43266274246635256], ...</td>\n",
       "      <td>[[0.5046573489605529], [0.40291922279431297], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[[-16.8117790363349, -10.0044179998228, -3.38...</td>\n",
       "      <td>[[0.00036290359642143706], [0.0936400726867578...</td>\n",
       "      <td>[[0.00560706454770033], [0.10915922223985002],...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[[13.4900336351284, -2.60190054263718, -1.001...</td>\n",
       "      <td>[[0.06596011311037349], [0.5684434259091489], ...</td>\n",
       "      <td>[[0.0709008177199287], [0.5803498015790439], [...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[[-1.7108286350794097, 9.39642148471085, 11.1...</td>\n",
       "      <td>[[0.2292788131518387], [0.16248023674493234], ...</td>\n",
       "      <td>[[0.204454114023573], [0.233062483490389], [0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[[[2.54684634599772, 1.06977998064985, 0.23069...</td>\n",
       "      <td>[[0.049066321437711446], [0.4018047859637618],...</td>\n",
       "      <td>[[0.0619881544687333], [0.325993305188003], [0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             h_input  \\\n",
       "1  [[[-0.512947407036421, 0.6178872998767779, 51....   \n",
       "2  [[[-16.8117790363349, -10.0044179998228, -3.38...   \n",
       "3  [[[13.4900336351284, -2.60190054263718, -1.001...   \n",
       "4  [[[-1.7108286350794097, 9.39642148471085, 11.1...   \n",
       "5  [[[2.54684634599772, 1.06977998064985, 0.23069...   \n",
       "\n",
       "                                           q_predict  \\\n",
       "1  [[0.5244445961101116], [0.43266274246635256], ...   \n",
       "2  [[0.00036290359642143706], [0.0936400726867578...   \n",
       "3  [[0.06596011311037349], [0.5684434259091489], ...   \n",
       "4  [[0.2292788131518387], [0.16248023674493234], ...   \n",
       "5  [[0.049066321437711446], [0.4018047859637618],...   \n",
       "\n",
       "                                              q_real  \n",
       "1  [[0.5046573489605529], [0.40291922279431297], ...  \n",
       "2  [[0.00560706454770033], [0.10915922223985002],...  \n",
       "3  [[0.0709008177199287], [0.5803498015790439], [...  \n",
       "4  [[0.204454114023573], [0.233062483490389], [0....  \n",
       "5  [[0.0619881544687333], [0.325993305188003], [0...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_list=[]\n",
    "qpred_list=[]\n",
    "qexp_list=[]\n",
    "for i in range(200):\n",
    "    h_list.append(inputs_c.tolist()[i])\n",
    "    qexp_list.append(target_c.tolist()[i])\n",
    "    qpred_list.append(qq_pred.tolist()[i])\n",
    "data_200={'h_input': h_list, 'q_predict': qpred_list,'q_real':qexp_list} \n",
    "df_200=pd.DataFrame(data_200)  \n",
    "df_200.index+=1\n",
    "df_200.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ -16.81177904  -10.004418     -3.38962921    8.4221353    23.47718958\n",
      "     -2.39255387    5.54909506    6.8309916   -81.21883192  -37.93005075\n",
      "     -7.74364308    3.25948654   57.93467303  -19.89156712   12.10430475\n",
      "     -6.90877518 -107.90977603  -24.50755992   12.03160419   -3.713654\n",
      "   -127.62654664    8.13606902   16.7007179     7.72990122]\n",
      "  [ -81.92182861   -3.60758854    2.00822605   -3.96455647  -70.03189398\n",
      "      7.89107869   -3.56663283   -8.52139244   -5.42776396  -15.53090556\n",
      "    -11.6021684     3.82845756  -32.00971682    9.0200967   -11.4143996\n",
      "     -6.7129745   148.38339798   -2.24493977   -8.21423231   17.90405598\n",
      "     72.87698679   15.24517797   -5.93196682    1.67728952]]]\n"
     ]
    }
   ],
   "source": [
    "print(np.array(df_200.iloc[1]['h_input']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_200.to_csv('list_200_for_recovery.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
